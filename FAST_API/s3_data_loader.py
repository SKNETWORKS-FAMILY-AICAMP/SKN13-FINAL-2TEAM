import boto3
import pandas as pd
import numpy as np
import os
from typing import List, Dict, Optional
from botocore.exceptions import NoCredentialsError, ClientError
import json
import io

class S3DataLoader:
    """S3ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” í´ëž˜ìŠ¤"""
    
    def __init__(self):
        self.aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID')
        self.aws_secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY') 
        self.aws_region = os.getenv('AWS_REGION', 'ap-northeast-2')
        self.bucket_name = os.getenv('S3_BUCKET_NAME')
        
        try:
            self.s3_client = boto3.client(
                's3',
                aws_access_key_id=self.aws_access_key_id,
                aws_secret_access_key=self.aws_secret_access_key,
                region_name=self.aws_region
            )
            print(f"âœ… S3 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ: {self.bucket_name}")
        except Exception as e:
            print(f"âŒ S3 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.s3_client = None
    
    def load_csv_from_s3(self, file_key: str) -> pd.DataFrame:
        """S3ì—ì„œ CSV íŒŒì¼ì„ ì½ì–´ì„œ DataFrameìœ¼ë¡œ ë°˜í™˜"""
        try:
            if not self.s3_client:
                raise Exception("S3 í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            response = self.s3_client.get_object(Bucket=self.bucket_name, Key=file_key)
            csv_content = response['Body'].read()
            df = pd.read_csv(io.StringIO(csv_content.decode('utf-8')))
            print(f"âœ… S3 ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}í–‰, {len(df.columns)}ì—´")
            return df
            
        except Exception as e:
            print(f"âŒ S3 íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return pd.DataFrame()

    def fix_image_url(self, url: str) -> str:
        """
        ì´ë¯¸ì§€ URLì„ ì˜¬ë°”ë¥¸ ì›¹ ì ‘ê·¼ ê°€ëŠ¥ í˜•ì‹ìœ¼ë¡œ ìˆ˜ì •í•˜ê³ , ë¬¸ì œê°€ ë  ìˆ˜ ìžˆëŠ” URLì„ ë¡œê¹…í•©ë‹ˆë‹¤.
        """
        if pd.isna(url) or not isinstance(url, str) or not url.strip():
            return ""

        original_url = url.strip()
        fixed_url = original_url

        # Case 1: "https://images/goods_img/..." ì™€ ê°™ì´ ìž˜ëª»ëœ ë„ë©”ì¸ì´ í¬í•¨ëœ ê²½ìš°
        if "images/goods_img/" in fixed_url:
            # "images/goods_img/" ì´í›„ì˜ ê²½ë¡œë§Œ ì¶”ì¶œ
            path_part = fixed_url.split("images/goods_img/")[-1]
            fixed_url = f"https://image.msscdn.net/thumbnails/images/goods_img/{path_part}"

        # Case 2: "//"ë¡œ ì‹œìž‘í•˜ëŠ” ê²½ìš°
        elif fixed_url.startswith("//"):
            fixed_url = f"https:{fixed_url}"
        
        # Case 3: "https:/" ì™€ ê°™ì´ ì˜¤íƒ€ê°€ ìžˆëŠ” ê²½ìš°
        elif fixed_url.startswith("https:/") and not fixed_url.startswith("https://"):
            fixed_url = fixed_url.replace("https:/", "https://", 1)

        # ìµœì¢… URLì´ httpë¡œ ì‹œìž‘í•˜ì§€ ì•Šìœ¼ë©´ ê²½ê³  ë¡œê¹… (ìˆ˜ì • í›„ì—ë„ ì—¬ì „ížˆ ë¬¸ì œì¸ ê²½ìš°)
        if not fixed_url.startswith(("http://", "https://")):
            print(f"âš ï¸ [URL ê²½ê³ ] ìµœì¢… URLì´ ìœ íš¨í•œ í”„ë¡œí† ì½œë¡œ ì‹œìž‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: '{fixed_url}' (ì›ë³¸: '{original_url}')")

        # ì›ë³¸ê³¼ ìˆ˜ì •ëœ URLì´ ë‹¤ë¥¸ ê²½ìš° ë¡œê¹…
        if original_url != fixed_url:
            print(f"ðŸ”§ [URL ìˆ˜ì •] ì›ë³¸: '{original_url}' -> ìˆ˜ì •: '{fixed_url}'")
            
        return fixed_url

    def load_product_data(self, file_key: str, use_cache: bool = True) -> List[Dict]:
        """ì œí’ˆ ë°ì´í„°ë¥¼ S3ì—ì„œ ë¡œë“œí•˜ê³  ê°€ê³µí•˜ì—¬ ë°˜í™˜ (ìºì‹± ì§€ì› ë° ìƒì„¸ ë¡œê¹…)"""
        from cache_manager import cache_manager
        # ìºì‹œ ì‹ë³„ìžì— ë²„ì „(_v2)ì„ ì¶”ê°€í•˜ì—¬ ì´ì „ ìºì‹œë¥¼ ë¬´íš¨í™”í•©ë‹ˆë‹¤.
        cache_identifier = f"s3_products_{self.bucket_name}_{file_key}_v2"
        
        if use_cache:
            cached_data = cache_manager.get(cache_identifier)
            if cached_data:
                print(f"âœ… ìºì‹œ(v2)ì—ì„œ '{cache_identifier}' ë°ì´í„°ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
                return cached_data
        
        print(f"â„¹ï¸ ìºì‹œì— ë°ì´í„°ê°€ ì—†ì–´ S3ì—ì„œ ì§ì ‘ ë¡œë“œí•©ë‹ˆë‹¤: {file_key}")
        try:
            df = self.load_csv_from_s3(file_key)
            if df.empty:
                return []
            
            df = df.replace({np.nan: None})
            
            image_col = next((col for col in ['ì‚¬ì§„', 'ëŒ€í‘œì´ë¯¸ì§€URL'] if col in df.columns), None)

            if image_col:
                print(f"ðŸ–¼ï¸ '{image_col}' ì»¬ëŸ¼ì˜ ì´ë¯¸ì§€ URLì„ ì²˜ë¦¬í•©ë‹ˆë‹¤...")
                df['fixed_image_url'] = df[image_col].apply(self.fix_image_url)
            else:
                print("âš ï¸ ì´ë¯¸ì§€ URL ì»¬ëŸ¼('ì‚¬ì§„' ë˜ëŠ” 'ëŒ€í‘œì´ë¯¸ì§€URL')ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                df['fixed_image_url'] = ""

            raw_data = df.to_dict("records")
            
            clothing_data = []
            for item in raw_data:
                mapped_item = {
                    "ìƒí’ˆëª…": item.get("ì œí’ˆì´ë¦„", item.get("ìƒí’ˆëª…", "")),
                    "ë¸Œëžœë“œ": item.get("ë¸Œëžœë“œ", ""),
                    "ê°€ê²©": item.get("ê°€ê²©", 0),
                    "ì‚¬ì§„": item.get('fixed_image_url', ''),
                }
                clothing_data.append(mapped_item)
            
            print(f"âœ… ì œí’ˆ ë°ì´í„° ê°€ê³µ ì™„ë£Œ: {len(clothing_data)}ê°œ ìƒí’ˆ")
            
            if use_cache and clothing_data:
                cache_manager.set(cache_identifier, clothing_data)
                print(f"ðŸ’¾ ê°€ê³µëœ ë°ì´í„°ë¥¼ ìºì‹œì— ì €ìž¥í–ˆìŠµë‹ˆë‹¤: '{cache_identifier}'")
            
            return clothing_data
            
        except Exception as e:
            print(f"âŒ ì œí’ˆ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []

s3_loader = S3DataLoader()

def get_product_data_from_s3(file_key: str) -> List[Dict]:
    return s3_loader.load_product_data(file_key)
