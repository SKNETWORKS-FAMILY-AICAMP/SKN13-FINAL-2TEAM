import os
import json
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from openai import OpenAI
from dotenv import load_dotenv
import asyncio

# Agent imports
from services.agents.search_agent import SearchAgent, SearchAgentResult
from services.agents.conversation_agent import ConversationAgent, ConversationAgentResult
from services.agents.weather_agent import WeatherAgent, WeatherAgentResult
from services.agents.general_agent import GeneralAgent, GeneralAgentResult
from services.agents.unified_summary_agent import UnifiedSummaryAgent, UnifiedSummaryResult
from services.agents.followup_agent import FollowUpAgent, FollowUpAgentResult

# Legacy imports for compatibility
# Legacy IntentAnalyzer ì œê±°ë¨ - í˜„ì¬ MainAnalyzerë§Œ ì‚¬ìš©
# clothing_recommenderëŠ” ì‚­ì œë˜ì—ˆìœ¼ë¯€ë¡œ WeatherAgentì˜ ë©”ì„œë“œ ì‚¬ìš©
# Legacy imports ì™„ì „ ì œê±°ë¨ - ëª¨ë“  ê¸°ëŠ¥ì´ ì—ì´ì „íŠ¸ë¡œ í†µí•©ë¨
from crud.chat_crud import (get_recent_qa_summaries, get_qa_pair_for_summary, 
                           update_message_summary, get_chat_history_for_llm)
from utils.safe_utils import safe_lower

load_dotenv()

# IntentResult í´ë˜ìŠ¤ ì •ì˜ (ê¸°ì¡´ intent_analyzerì—ì„œ ì´ë™)
@dataclass
class IntentResult:
    intent: str  # 'search', 'conversation', 'followup', 'weather', 'general'
    confidence: float
    extracted_info: Dict
    original_query: str

@dataclass
class LangGraphState:
    """LangGraph ìƒíƒœ ê´€ë¦¬"""
    user_input: str
    session_id: str  # UUIDë¥¼ ë¬¸ìì—´ë¡œ ì²˜ë¦¬
    user_id: int
    intent: str = ""
    extracted_info: Dict = None
    context_summaries: List[str] = None
    agent_result: Any = None
    final_message: str = ""
    products: List[Dict] = None
    available_products: List[Dict] = None
    latitude: Optional[float] = None
    longitude: Optional[float] = None
    
    def __post_init__(self):
        if self.extracted_info is None:
            self.extracted_info = {}
        if self.context_summaries is None:
            self.context_summaries = []
        if self.products is None:
            self.products = []

@dataclass
class LLMResponse:
    """LLM ì‘ë‹µ êµ¬ì¡°"""
    final_message: str
    products: List[Dict]
    analysis_result: Any  # IntentResult ë˜ëŠ” MainAnalysisResult
    summary_result: Optional[UnifiedSummaryResult] = None
    metadata: Dict = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}



class MainAnalyzer:
    """ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ë©”ì¸ ë¶„ì„ê¸° (ì»¨í…ìŠ¤íŠ¸ í¬í•¨ ì˜ë„ ë¶„ì„ìš©)"""
    
    def __init__(self):
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.model = "gpt-4o"
        
        # ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œë“¤ (ëª¨ì, ì•¡ì„¸ì„œë¦¬, ì‹ ë°œ ë“±)
        self.unsupported_categories = {
            # ëª¨ìë¥˜
            "ëª¨ì", "ìº¡", "ì•¼êµ¬ëª¨ì", "ë¹„ë‹ˆ", "ë² ë ˆëª¨", "í—¬ë©§", "hat", "cap", "beanie", "beret",
            
            # ì•¡ì„¸ì„œë¦¬
            "ëª©ê±¸ì´", "íŒ”ì°Œ", "ë°˜ì§€", "ê·€ê±¸ì´", "ì‹œê³„", "ë²¨íŠ¸", "ë„¥íƒ€ì´", "bow tie", "ìŠ¤ì¹´í”„", "ë¨¸í”ŒëŸ¬",
            "necklace", "bracelet", "ring", "earring", "watch", "belt", "tie", "scarf", "muffler",
            
            # ì‹ ë°œë¥˜
            "ì‹ ë°œ", "êµ¬ë‘", "ìš´ë™í™”", "ë¶€ì¸ ", "ìƒŒë“¤", "ìŠ¬ë¦¬í¼", "ë¡œí¼", "í", "í”Œë«", "ìŠ¤ë‹ˆì»¤ì¦ˆ",
            "shoes", "sneakers", "boots", "sandals", "slippers", "loafers", "heels", "flats",
            
            # ê°€ë°©ë¥˜
            "ê°€ë°©", "ë°±íŒ©", "í•¸ë“œë°±", "í´ëŸ¬ì¹˜", "í† íŠ¸ë°±", "í¬ë¡œìŠ¤ë°±", "ìˆ„ë”ë°±", "ì§€ê°‘",
            "bag", "backpack", "handbag", "clutch", "tote", "crossbody", "shoulder bag", "wallet",
            
            # ê¸°íƒ€ ì•¡ì„¸ì„œë¦¬
            "ì„ ê¸€ë¼ìŠ¤", "ì•ˆê²½", "ë§ˆìŠ¤í¬", "ì¥ê°‘", "ì–‘ë§", "ìŠ¤íƒ€í‚¹", "ì†ì˜·", "ì–¸ë”ì›¨ì–´",
            "sunglasses", "glasses", "mask", "gloves", "socks", "stockings", "underwear"
        }
        
        # ì§€ì›í•˜ëŠ” ì¹´í…Œê³ ë¦¬ (í™•ì¸ìš©)
        self.supported_categories = {
            "ìƒì˜", "ë°”ì§€", "ìŠ¤ì»¤íŠ¸", "ì›í”¼ìŠ¤", "top", "pants", "skirt", "dress",
            "ê¸´ì†Œë§¤", "ë°˜ì†Œë§¤", "í›„ë“œí‹°", "ë‹ˆíŠ¸", "ìŠ¤ì›¨í„°", "ì…”ì¸ ", "ë¸”ë¼ìš°ìŠ¤", "í”¼ì¼€", "ì¹´ë¼", "ìŠ¬ë¦¬ë¸Œë¦¬ìŠ¤",
            "ë°ë‹˜íŒ¬ì¸ ", "ì½”íŠ¼íŒ¬ì¸ ", "ìŠˆíŠ¸íŒ¬ì¸ ", "ìŠ¬ë™ìŠ¤", "ì¹´ê³ íŒ¬ì¸ ", "íŠ¸ë ˆì´ë‹íŒ¬ì¸ ", "ì¡°ê±°íŒ¬ì¸ ", "ìˆíŒ¬ì¸ ",
            "ë¯¸ë‹ˆìŠ¤ì»¤íŠ¸", "ë¯¸ë””ìŠ¤ì»¤íŠ¸", "ë¡±ìŠ¤ì»¤íŠ¸", "ë§¥ì‹œì›í”¼ìŠ¤", "ë¯¸ë‹ˆì›í”¼ìŠ¤", "ë¯¸ë””ì›í”¼ìŠ¤"
        }
    
    def analyze_with_prompt(self, user_input: str, context: str = "", session_summary: str = "") -> Dict:
        """í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ìœ¼ë¡œ intent ë¶„ë¥˜ë§Œ ìˆ˜í–‰"""
        
        print(f"ğŸ” Intent ë¶„ë¥˜ ì‹œì‘: '{user_input}'")
        print(f"ğŸ“ ì»¨í…ìŠ¤íŠ¸: {context[:100]}..." if context else "ğŸ“ ì»¨í…ìŠ¤íŠ¸: ì—†ìŒ")
        
        # ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¹´í…Œê³ ë¦¬ ì²´í¬
        unsupported_detected = self._check_unsupported_categories(user_input)
        if unsupported_detected:
            print(f"ğŸš« ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¹´í…Œê³ ë¦¬ ê°ì§€: {unsupported_detected}")
            return {
                "intent": "general",
                "analysis_summary": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¹´í…Œê³ ë¦¬({unsupported_detected}) ìš”ì²­ìœ¼ë¡œ general intentë¡œ ë¶„ë¥˜"
            }
        
        system_prompt = """ë‹¹ì‹ ì€ ì˜ë¥˜ ì¶”ì²œ ì‹œìŠ¤í…œì˜ intent ë¶„ë¥˜ê¸°ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ intentë§Œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸ ì •ë³´:
- ì´ì „ ëŒ€í™” ë‚´ìš©: {context}
- ì„¸ì…˜ ìš”ì•½: {session_summary}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
    "intent": "search|conversation|followup|weather|general",
    "analysis_summary": "intent ë¶„ë¥˜ ê·¼ê±°"
}}

Intent ë¶„ë¥˜ ê¸°ì¤€:
- search: êµ¬ì²´ì ì¸ ìƒí’ˆ ê²€ìƒ‰ ("íŒŒë€ìƒ‰ ì…”ì¸ ", "ì²­ë°”ì§€ ì¶”ì²œ", "ë‚˜ì´í‚¤ ìš´ë™í™”", "ë¹¨ê°„ìƒ‰ í‹°ì…”ì¸ ", "ê²€ì€ìƒ‰ ë°”ì§€")
- conversation: ìƒí™©ë³„ ì¶”ì²œ ("ë°ì´íŠ¸ë£©", "ë©´ì ‘ë³µ", "íŒŒí‹°ë£©", "ê²°í˜¼ì‹ ê°ˆ ë•Œ ì˜· ì¶”ì²œ", "ì¶œê·¼ë³µ") 
- followup: ì´ì „ ì¶”ì²œì— ëŒ€í•œ í›„ì† ì§ˆë¬¸ ("ì´ê²ƒë“¤ì¤‘ì— ì œì¼ ì‹¼ê±°", "ë” ë¹„ì‹¼ ê²ƒë„ ìˆì–´?", "ì²« ë²ˆì§¸ê°€ ì¢‹ì„ê¹Œ?", "ë‹¤ë¥¸ ìƒ‰ìƒì€?")
- weather: ë‚ ì”¨ ê´€ë ¨ ("ì˜¤ëŠ˜ ë‚ ì”¨", "ì„œìš¸ ë‚ ì”¨", "ë¹„ ì˜¬ ë•Œ ì…ì„ ì˜·")
- general: ë‹¨ìˆœ ì¸ì‚¬/ì¡ë‹´ ("ì•ˆë…•", "ê³ ë§ˆì›Œ", "ã…ã…") â†’ ì¶”ì²œ/ê²€ìƒ‰/ë‚ ì”¨/í›„ì†ì§ˆë¬¸ì´ ì „í˜€ ì•„ë‹ ë•Œë§Œ í•´ë‹¹

**ì¤‘ìš”**: 
1. ë‚ ì”¨ì™€ ìƒí™©ì´ í•¨ê»˜ ì–¸ê¸‰ë  ì‹œ weatherë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.
2. ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì´ì „ì— ìƒí’ˆ ì¶”ì²œê³¼ ì—°ê´€ì´ ìˆëŠ” ì§ˆë¬¸ì´ë¼ë©´, ê·¸ ìƒí’ˆë“¤ì— ëŒ€í•œ ì§ˆë¬¸ì€ ë°˜ë“œì‹œ 'followup'ìœ¼ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.
3. generalì€ ì •ë§ ë‹¨ìˆœí•œ ì¸ì‚¬ë‚˜ ì˜ë¥˜ì™€ ì „í˜€ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì¼ ë•Œë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
"""
        messages = [
            {"role": "system", "content": system_prompt.format(
                context=context,
                session_summary=session_summary
            )},
            {"role": "user", "content": f"ì‚¬ìš©ì ì…ë ¥: {user_input}"}
        ]
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.1,  # ë” ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•´ ë‚®ì¶¤
                max_tokens=500,
                response_format={"type": "json_object"}  # JSON í˜•ì‹ ê°•ì œ
            )
            
            raw_response = response.choices[0].message.content
            print(f"ğŸ¤– LLM ì›ë³¸ ì‘ë‹µ: {raw_response}")
            
            result = json.loads(raw_response)
            print(f"âœ… Intent ë¶„ë¥˜ ê²°ê³¼: {result.get('intent', 'unknown')} - {result.get('analysis_summary', '')}")
            
            return result
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            print(f"ì›ë³¸ ì‘ë‹µ: {raw_response}")
            return {
                "intent": "search",  # ì˜¤ë¥˜ ì‹œ searchë¡œ fallback (ë” ìœ ìš©í•¨)
                "analysis_summary": f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}"
            }
        except Exception as e:
            print(f"âŒ ë©”ì¸ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {
                "intent": "search",  # ì˜¤ë¥˜ ì‹œ searchë¡œ fallback
                "analysis_summary": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }
    
    def _check_unsupported_categories(self, user_input: str) -> Optional[str]:
        """ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œë¥¼ ê°ì§€"""
        user_lower = user_input.lower()
        
        # ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ ì²´í¬
        for category in self.unsupported_categories:
            if category.lower() in user_lower:
                return category
        
        return None



class LLMService:
    """LangGraph ê¸°ë°˜ LLM ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        # Core analyzers (ë©”ëª¨ë¦¬ ë¶„ì„ê¸° ì œê±°, ë©”ì¸ ë¶„ì„ê¸°ë§Œ ì‚¬ìš©)
        self.main_analyzer = MainAnalyzer()
        
        # Specialized agents
        self.search_agent = SearchAgent()
        self.conversation_agent = ConversationAgent()
        self.weather_agent = WeatherAgent()
        self.general_agent = GeneralAgent()
        self.unified_summary_agent = UnifiedSummaryAgent()
        self.followup_agent = FollowUpAgent()
        print("âœ… FollowUpAgent ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ê¸°ì¡´ IntentAnalyzer ì œê±° - í•­ìƒ MainAnalyzer ì‚¬ìš©
    
    async def process_user_input(self, user_input: str, session_id: str, user_id: int, 
                                available_products: List[Dict], db=None, 
                                latitude: Optional[float] = None, 
                                longitude: Optional[float] = None) -> LLMResponse:
        """LangGraph ìŠ¤íƒ€ì¼ë¡œ ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬"""
        

        
        # ì´ˆê¸° ìƒíƒœ ìƒì„±
        state = LangGraphState(
            user_input=user_input,
            session_id=session_id,
            user_id=user_id,
            available_products=available_products,
            latitude=latitude,
            longitude=longitude
        )
        
        # LangGraph ìŠ¤íƒ€ì¼ ì²˜ë¦¬ í”Œë¡œìš°
        state = await self._memory_analysis_node(state, db)
        state = await self._intent_analysis_node(state, db)
        state = await self._agent_execution_node(state, available_products, db)
        state = await self._summary_update_node(state, db)
        
        # ë¶„ì„ ê²°ê³¼ êµ¬ì„± (í•­ìƒ IntentResultë¡œ í†µì¼)
        
        # í•­ìƒ IntentResultë¡œ í†µì¼
        analysis_result = IntentResult(
            intent=state.intent,
            confidence=1.0,
            extracted_info=state.extracted_info if hasattr(state, 'extracted_info') else {},
            original_query=state.user_input
        )

        # ìµœì¢… ì‘ë‹µ êµ¬ì„±
        return LLMResponse(
            final_message=state.final_message,
            products=state.products,
            analysis_result=analysis_result,
            summary_result=state.summary_result if hasattr(state, 'summary_result') else None,
            metadata={
                "intent": state.intent,
                "always_uses_context": True,
                "agent_type": getattr(analysis_result, 'metadata', {}).get('agent_type', state.intent),
                "context_summaries_count": len(state.context_summaries)
            }
        )
    
    async def _memory_analysis_node(self, state: LangGraphState, db) -> LangGraphState:
        """ë©”ëª¨ë¦¬ ë¡œë“œ ë…¸ë“œ - í•­ìƒ ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ"""
        if db:
            state.context_summaries = get_recent_qa_summaries(db, state.session_id, limit=3)
        else:
            state.context_summaries = []
        
        return state
    
    async def _intent_analysis_node(self, state: LangGraphState, db) -> LangGraphState:
        """ì˜ë„ ë¶„ì„ ë…¸ë“œ - intent ë¶„ë¥˜ë§Œ ìˆ˜í–‰"""
        context_str = " | ".join(state.context_summaries) if state.context_summaries else "ì´ì „ ëŒ€í™” ì—†ìŒ"
        
        print(f"ğŸ¯ Intent ë¶„ì„ ë…¸ë“œ ì‹œì‘")
        print(f"   ì‚¬ìš©ì ì…ë ¥: '{state.user_input}'")
        print(f"   ì»¨í…ìŠ¤íŠ¸: {context_str[:100]}..." if context_str != "ì´ì „ ëŒ€í™” ì—†ìŒ" else "   ì»¨í…ìŠ¤íŠ¸: ì—†ìŒ")
        
        analysis_result = self.main_analyzer.analyze_with_prompt(
            state.user_input, context_str, ""
        )
        
        state.intent = analysis_result.get("intent", "general")
        print(f"ğŸ¯ ìµœì¢… Intent: {state.intent}")
        
        # extracted_infoëŠ” ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì´ˆê¸°í™” (í•„í„°ë§ ì¡°ê±´ì€ ê° Agentì—ì„œ ì²˜ë¦¬)
        state.extracted_info = {}
        
        return state
    
    async def _agent_execution_node(self, state: LangGraphState, available_products: List[Dict], db) -> LangGraphState:
        """Agent ì‹¤í–‰ ë…¸ë“œ - ì˜ë„ì— ë”°ë¼ ì ì ˆí•œ Agent í˜¸ì¶œ"""
        print(f"ğŸ¤– Agent ì‹¤í–‰ ë…¸ë“œ ì‹œì‘ - Intent: {state.intent}")
        
        try:
            if state.intent == "followup":
                print("ğŸ“ FollowUp Agent ì‹¤í–‰")
                result = self.followup_agent.process_follow_up_question(
                    state.user_input, 
                    db, 
                    state.user_id,
                    state.session_id,
                    search_agent=self.search_agent,
                    available_products=state.available_products
                )
                
                state.agent_result = result
                state.final_message = result.message
                state.products = result.products
                
            elif state.intent == "search":
                print("ğŸ” Search Agent ì‹¤í–‰")
                # Search Agent ì‹¤í–‰
                result = self.search_agent.process_search_request(
                    state.user_input, 
                    available_products,
                    context_info={"previous_summaries": state.context_summaries} if state.context_summaries else None,
                    db=db,
                    user_id=state.user_id
                )
                state.agent_result = result
                state.final_message = result.message
                state.products = result.products
                
            elif state.intent == "conversation":
                print("ğŸ’¬ Conversation Agent ì‹¤í–‰")
                # Conversation Agent ì‹¤í–‰ (ìˆœìˆ˜ ìƒí™©ë³„ ì¶”ì²œë§Œ)
                result = self.conversation_agent.process_conversation_request(
                    state.user_input,
                    state.extracted_info,
                    available_products,
                    context_summaries=state.context_summaries,
                    db=db,
                    user_id=state.user_id
                )
                state.agent_result = result
                state.final_message = result.message
                state.products = result.products
                print(f"âœ… Conversation Agent ì™„ë£Œ: {len(result.products)}ê°œ ìƒí’ˆ")
                
            elif state.intent == "weather":
                print("ğŸŒ¤ï¸ Weather Agent ì‹¤í–‰")
                # Weather Agent ì‹¤í–‰ (ì‚¬ìš©ì ì„±ë³„ ì •ë³´ í•„ìš”)
                # TODO: ì‹¤ì œ ì‚¬ìš©ì ì •ë³´ì—ì„œ ì„±ë³„ ê°€ì ¸ì˜¤ê¸°
                user_gender = "ë‚¨ì„±"  # ì„ì‹œë¡œ "ë‚¨ì„±" ì‚¬ìš©
                
                result = await self.weather_agent.process_weather_request(
                    state.user_input,
                    state.extracted_info,
                    latitude=state.latitude,
                    longitude=state.longitude,
                    user_gender=user_gender
                )
                state.agent_result = result
                state.final_message = result.message
                state.products = result.products
                
            else:  # general
                print("ğŸ’­ General Agent ì‹¤í–‰")
                # General Agent ì‹¤í–‰
                result = self.general_agent.process_general_request(
                    state.user_input,
                    state.extracted_info,
                    context_summaries=state.context_summaries
                )
                state.agent_result = result
                state.final_message = result.message
                state.products = result.products
                
        except Exception as e:
            print(f"âŒ Agent ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            print(f"   Intent: {state.intent}")
            print(f"   ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
            import traceback
            print(f"   ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
            
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¼ë°˜ ì—ì´ì „íŠ¸ë¡œ fallback
            print("ğŸ”„ General Agentë¡œ fallback")
            try:
                result = self.general_agent.process_general_request(
                    state.user_input,
                    state.extracted_info if hasattr(state, 'extracted_info') else {},
                    context_summaries=state.context_summaries
                )
                state.agent_result = result
                state.final_message = result.message
                state.products = result.products
            except Exception as fallback_error:
                print(f"âŒ Fallbackë„ ì‹¤íŒ¨: {fallback_error}")
                state.final_message = "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                state.products = []
        
        return state
    
    async def _summary_update_node(self, state: LangGraphState, db) -> LangGraphState:
        """í†µí•© ìš”ì•½ ì—…ë°ì´íŠ¸ ë…¸ë“œ - LLM ìµœì¢… ë‹µë³€ê¹Œì§€ í¬í•¨í•œ ì™„ì „í•œ ìš”ì•½"""
        if not db:
            return state
        
        try:
            # ê¸°ì¡´ ìš”ì•½ ì¡°íšŒ
            existing_summary = None
            try:
                from crud.chat_crud import get_recent_qa_summaries
                recent_summaries = get_recent_qa_summaries(db, state.session_id, limit=1)
                if recent_summaries:
                    existing_summary = recent_summaries[0]
            except Exception:
                pass
            
            # í†µí•© ì„œë¨¸ë¦¬ ì—ì´ì „íŠ¸ë¡œ ì™„ì „í•œ Q/A ìš”ì•½ ìƒì„±
            summary_result = self.unified_summary_agent.process_complete_qa_summary(
                user_input=state.user_input,
                llm_final_response=state.final_message,
                existing_summary=existing_summary
            )
            
            # ìƒíƒœì— ìš”ì•½ ì •ë³´ ì €ì¥
            state.summary_to_save = summary_result.summary_text
            state.summary_result = summary_result
            
        except Exception:
            # ì˜¤ë¥˜ ì‹œ ê°„ë‹¨í•œ fallback ìš”ì•½ ìƒì„±
            fallback_summary = f"Q: {state.user_input[:30]}... â†’ A: {state.final_message[:50]}..."
            state.summary_to_save = fallback_summary
        
        return state
    
    # ë‚ ì”¨ ê´€ë ¨ ê¸°ëŠ¥ë“¤ì€ WeatherAgentë¡œ ì´ë™ë¨
        