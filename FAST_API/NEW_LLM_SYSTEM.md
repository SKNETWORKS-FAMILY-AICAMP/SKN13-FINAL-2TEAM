# 🤖 새로운 LLM 서비스 시스템

## 📋 개요

기존 LLM 서비스를 완전히 재설계하여 **메모리 기반 대화 시스템**으로 업그레이드했습니다. 사용자의 이전 대화 내용을 기억하고 컨텍스트를 고려한 더 정교한 의류 추천이 가능합니다.

## 🏗️ 시스템 아키텍처

### 새로운 플로우
```
사용자 입력 → 기억 필요 판단 → 분기 처리 → 응답 생성 → 세션 요약 업데이트
```

### 주요 컴포넌트

#### 1. **MemoryAnalyzer** (기억 필요 분석기)
- 사용자 입력에서 이전 대화 컨텍스트가 필요한지 판단
- 지시어, 비교어, 확장 요청 등을 감지

#### 2. **MainAnalyzer** (메인 분석기)
- 프롬프트 기반 종합 분석
- 대화 히스토리와 세션 요약을 활용한 컨텍스트 분석

#### 3. **EnhancedProductFilter** (향상된 필터)
- 기존 필터링에 컨텍스트 기반 추가 필터링
- 이전 추천과의 비교/대조 기능

#### 4. **SessionSummarizer** (세션 요약기)
- 대화 내용을 자동으로 요약
- 사용자 선호도 및 중요 정보 추출

## 🔄 처리 플로우

### 기억 필요 플로우
```
1. 최근 대화 히스토리 로드
2. 세션 요약 로드
3. 컨텍스트와 함께 LLM 재분석
4. 기존 데이터와 비교하여 향상된 필터링
5. 응답 생성
```

### 기억 불필요 플로우
```
1. 기존 Intent Analyzer 사용
2. 기존 Agent 기반 처리
3. 일반적인 필터링 및 검색
4. 응답 생성
```

## 📊 데이터베이스 변경사항

### ChatSession 테이블
```sql
-- 새로 추가된 컬럼
summary TEXT NULL  -- 대화 요약 저장
```

### 새로운 CRUD 함수
- `update_session_summary()` - 세션 요약 업데이트
- `get_session_summary()` - 세션 요약 조회

## 🚀 API 엔드포인트

### 새로운 챗봇 API
```
POST /chat-new/new
- 새로운 LLM 시스템을 사용한 챗봇 요청
- 기억 기반 처리 플로우 적용
```

### 분석 API
```
GET /chat-new/analysis/{session_id}
- 세션 분석 정보 조회
- 요약, 메시지 수, 생성/수정 시간 등

PUT /chat-new/session/{session_id}/summary
- 세션 요약 수동 업데이트

GET /chat-new/debug/memory-test
- 기억 필요 여부 판단 테스트 (디버깅용)
```

## 💡 주요 개선사항

### 1. **지능적 컨텍스트 분석**
- 이전 대화 내용을 고려한 의도 분류
- 사용자 선호도 기반 추천

### 2. **메모리 기반 대화**
- "이거 말고 다른 거", "비슷한 스타일" 등 모호한 요청 처리
- 이전 추천과의 비교/대조 기능

### 3. **세션 요약 시스템**
- 자동 대화 요약 생성
- 사용자 선호도 및 중요 정보 추출

### 4. **향상된 필터링**
- 기존 필터링 + 컨텍스트 기반 추가 필터링
- 이전 추천과 다른 브랜드/스타일 우선 추천

## 🔧 사용 예시

### 기억이 필요한 대화
```
사용자: "파란색 셔츠 추천해줘"
챗봇: [파란색 셔츠 추천]

사용자: "이거 말고 좀 더 캐주얼한 걸로"
→ 기억 필요 감지 → 이전 추천 고려 → 캐주얼 스타일 필터링
```

### 기억이 불필요한 대화
```
사용자: "빨간색 니트 추천해줘"
→ 기억 불필요 → 기존 Agent 플로우 → 직접 검색
```

## 🛠️ 설치 및 실행

### 환경 설정
```bash
# 환경변수 확인
OPENAI_API_KEY=your_openai_api_key

# 데이터베이스 마이그레이션 (summary 컬럼 추가)
# 수동으로 ALTER TABLE chat_session ADD COLUMN summary TEXT;
```

### 테스트 실행
```bash
python test_new_llm.py
```

### 서버 실행
```bash
python main.py
```

## 📈 성능 모니터링

### 주요 지표
- 기억 필요 판단 정확도
- 컨텍스트 활용 응답 품질
- 세션 요약 품질
- 사용자 만족도

### 로그 모니터링
```python
# 각 단계별 로그 출력
print(f"기억 필요: {needs_memory}")
print(f"의도 분석 결과: {intent}")
print(f"컨텍스트 길이: {len(context)}")
```

## 🔍 디버깅 도구

### 메모리 테스트
```bash
GET /chat-new/debug/memory-test?test_input=이거 말고 다른 거 추천해줘
```

### 세션 분석
```bash
GET /chat-new/analysis/123
```

## 🚨 주의사항

1. **토큰 사용량 증가**
   - 컨텍스트와 요약을 포함하여 LLM 호출 시 토큰 사용량 증가
   - 비용 모니터링 필요

2. **응답 시간**
   - 기억 기반 플로우는 추가 LLM 호출로 인해 응답 시간 증가 가능

3. **데이터베이스 크기**
   - 세션 요약 저장으로 인한 저장 공간 증가

## 🔄 향후 개선 계획

1. **캐싱 시스템**
   - 자주 사용되는 분석 결과 캐싱

2. **배치 처리**
   - 세션 요약을 배치로 생성하여 실시간 성능 향상

3. **사용자 피드백**
   - 추천 품질에 대한 사용자 피드백 수집 및 학습

4. **다국어 지원**
   - 영어 등 다른 언어 지원 확장
