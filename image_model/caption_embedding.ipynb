{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ed95d81",
   "metadata": {},
   "source": [
    "# 캡션 생성 : gpt-4o-mini를 통해 crop 된 이미지의 캡션을 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6eb50c",
   "metadata": {},
   "source": [
    "## top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e62993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Stage 1: 이미지 → GPT-4o-mini 태깅 → CSV 저장\n",
    "# - 결과 CSV: top_caption.csv  (columns: product_id, combined_text)\n",
    "# - category/type은 원본 CSV(top.csv)에서 조회\n",
    "# - top (상의)만 처리\n",
    "\n",
    "import os, re, io, base64, asyncio\n",
    "from typing import List, Dict, Tuple\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "# ================== 경로/환경 ==================\n",
    "IMAGE_DIR = \"crop_29cm\"\n",
    "PRODUCT_INFO_CSV = \"29cm/29cm_1000.csv\"\n",
    "OUT_CSV = \"29cm/top_caption.csv\"\n",
    "\n",
    "MAX_SIDE = 768\n",
    "JPEG_QUALITY = 85\n",
    "MAX_CONCURRENCY = 4\n",
    "\n",
    "load_dotenv()\n",
    "aclient = AsyncOpenAI()  # OPENAI_API_KEY 필요\n",
    "\n",
    "# ================== key 목록 ==================\n",
    "TOK_KEYS = [\n",
    "    \"color.main\",\"color.sub\",\"pattern\",\"pattern_scale\",\"material.fabric\",\n",
    "    \"sleeve.length\",\"sleeve.width\",\"sleeve.style\",\"fit\",\"neckline\",\"collar\",\n",
    "    \"closure\",\"graphic\",\"graphic_position\",\"graphic_size\",\"length.top\",\n",
    "    \"sleeve.cuff\",\"shoulder\"\n",
    "]\n",
    "\n",
    "# ================== GPT 프롬프트 ==================\n",
    "PROMPT = \"\"\"\n",
    "You are a fashion vision tagger for tops (e.g., t-shirt, hoodie, blouse, sweater, sleeveless, athleisure).\n",
    "Analyze ONLY the top garment. Ignore accessories, pants, skirts, skin, hair, or background.\n",
    "If the attribute truly does not exist, output \"none\".\n",
    "\n",
    "Return EXACTLY 18 lowercase, comma-separated tokens as key=value pairs,\n",
    "using these keys IN THIS ORDER (keys must match exactly; no extra fields):\n",
    "\n",
    "1) color.main\n",
    "   black / white / gray / beige / cream / brown / navy / blue / green / yellow / orange / red / pink / purple / unknown\n",
    "2) color.sub\n",
    "   second-most visible (≥15% of garment area) else none\n",
    "3) pattern\n",
    "   solid / stripe / check / houndstooth / herringbone / dot / floral / paisley / animal / camouflage / text / scenic / logo / geometric / abstract / lace-knit / mixed / unknown\n",
    "4) pattern_scale\n",
    "   small / medium / large / none / unknown   (if pattern=solid ⇒ none)\n",
    "5) material.fabric\n",
    "   knit / denim / leather / suede / corduroy / chiffon / satin / lace / tweed / wool-blend / woven-cotton / woven-poly / other / unknown\n",
    "6) sleeve.length\n",
    "   sleeveless / short / half / three-quarter / long / unknown\n",
    "7) sleeve.width\n",
    "   slim / regular / wide / unknown\n",
    "8) sleeve.style\n",
    "   none / puff / balloon / raglan / kimono / off-shoulder / cold-shoulder / bishop / roll-up / spaghetti / tank / unknown\n",
    "9) fit\n",
    "   slim / regular / oversized / unknown\n",
    "10) neckline\n",
    "   round / v / square / halter / off-shoulder / strapless / cowl / one-shoulder / boat / unknown\n",
    "11) collar\n",
    "   none / shirt / polo / mandarin / high-neck / hood / unknown\n",
    "12) closure\n",
    "   zipper / buttons / hooks / drawstring / pullover / none / unknown\n",
    "13) graphic\n",
    "   none / logo / text / image / photo / art / abstract / all-over / unknown\n",
    "14) graphic_position\n",
    "   chest / sleeve / back / hem / multi / center / none / unknown\n",
    "15) graphic_size\n",
    "   small / medium / large / all-over / none / unknown\n",
    "16) length.top\n",
    "   cropped / regular / longline / tunic / unknown\n",
    "17) sleeve.cuff\n",
    "   plain / ribbed / elastic / buttoned / rolled / none / unknown\n",
    "18) shoulder\n",
    "   dropped / raglan / regular / padded / off-shoulder / one-shoulder / unknown\n",
    "\n",
    "---\n",
    "\n",
    "CONSISTENCY RULES\n",
    "- if pattern=solid ⇒ pattern_scale=none\n",
    "- if graphic=none ⇒ graphic_position=none and graphic_size=none\n",
    "- if graphic=all-over ⇒ pattern=solid\n",
    "- if pattern ≠ solid and graphic ≠ none ⇒ both can coexist (e.g., floral shirt with chest logo)\n",
    "- if sleeve.length=sleeveless and sleeve.style in {spaghetti, tank} ⇒ keep both\n",
    "- neckline and collar are independent; use none if not present\n",
    "- When unsure, output \"unknown\"\n",
    "\n",
    "---\n",
    "\n",
    "FORMAT GUARD\n",
    "- Exactly 18 tokens, lowercase, comma-separated\n",
    "- key=value for every token\n",
    "- No spaces around commas, no explanations\n",
    "- Example:\n",
    "  \"color.main=white,color.sub=none,pattern=solid,pattern_scale=none,material.fabric=knit,sleeve.length=short,sleeve.width=regular,sleeve.style=none,fit=slim,neckline=round,collar=shirt,closure=buttons,graphic=logo,graphic_position=chest,graphic_size=small,length.top=regular,sleeve.cuff=ribbed,shoulder=regular\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ================== 도우미 함수 ==================\n",
    "def image_to_b64(image_path: str, max_side: int = MAX_SIDE, jpeg_quality: int = JPEG_QUALITY):\n",
    "    im = Image.open(image_path).convert(\"RGB\")\n",
    "    w, h = im.size\n",
    "    scale = max(w, h) / float(max_side)\n",
    "    if scale > 1.0:\n",
    "        try: resample = Image.Resampling.BICUBIC\n",
    "        except AttributeError: resample = Image.BICUBIC\n",
    "        im = im.resize((int(w/scale), int(h/scale)), resample)\n",
    "    buf = io.BytesIO()\n",
    "    im.save(buf, format=\"JPEG\", quality=jpeg_quality, optimize=True)\n",
    "    return base64.b64encode(buf.getvalue()).decode(\"utf-8\"), \"image/jpeg\"\n",
    "\n",
    "# 파일명에서 product_id 추출\n",
    "PID_FROM_NAME = re.compile(r\"^top_([^.\\\\/]+)\", re.IGNORECASE)\n",
    "def extract_product_id_from_filename(path: str) -> str:\n",
    "    base = os.path.basename(path)\n",
    "    m = PID_FROM_NAME.search(base)\n",
    "    return (m.group(1) if m else \"\").strip().lower()\n",
    "\n",
    "# 제품 CSV 불러오기 (상의만)\n",
    "def load_top_map(csv_path: str) -> Dict[str, Tuple[str,str]]:\n",
    "    df = pd.read_csv(csv_path, dtype=str)\n",
    "    df = df.fillna(\"\").apply(lambda col: col.str.strip().str.lower())\n",
    "    df_top = df[df[\"대분류\"] == \"상의\"]  # top만 필터\n",
    "    return dict(zip(df_top[\"상품코드\"], zip(df_top[\"대분류\"], df_top[\"소분류\"])))\n",
    "\n",
    "def map_categories_and_sub(major: str, sub: str) -> Tuple[str, str]:\n",
    "    major_map = {\"상의\":\"top\"}\n",
    "    sub_map = {\n",
    "        \"후드티\":\"hoodie\",\"셔츠블라우스\":\"shirt-blouse\",\"긴소매\":\"longsleeve\",\n",
    "        \"반소매\":\"shortsleeve\",\"피케카라\":\"polo\",\"니트스웨터\":\"knit-sweater\",\n",
    "        \"슬리브리스\":\"sleeveless\"\n",
    "    }\n",
    "    return major_map.get(major, \"top\"), sub_map.get(sub, \"unknown\")\n",
    "\n",
    "# ================== normalize ==================\n",
    "def normalize_caption_18(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    text = \" \".join(text.splitlines()).strip().strip('\"').strip(\"'\")\n",
    "\n",
    "    # key=value 추출\n",
    "    raw_parts = [p.strip().lower() for p in text.split(\",\") if \"=\" in p]\n",
    "    kv_map = {}\n",
    "    for p in raw_parts:\n",
    "        if \"=\" in p:\n",
    "            k, v = p.split(\"=\", 1)\n",
    "            kv_map[k.strip()] = v.strip()\n",
    "\n",
    "    # 누락된 키 unknown 채우기\n",
    "    fixed = []\n",
    "    for k in TOK_KEYS:\n",
    "        val = kv_map.get(k, \"unknown\")\n",
    "        fixed.append(f\"{k}={val}\")\n",
    "\n",
    "    # 룰 보정\n",
    "    kv = {kv.split(\"=\")[0]: kv.split(\"=\")[1] for kv in fixed}\n",
    "    if kv[\"pattern\"] == \"solid\":\n",
    "        kv[\"pattern_scale\"] = \"none\"\n",
    "    if kv[\"graphic\"] == \"none\":\n",
    "        kv[\"graphic_position\"] = \"none\"\n",
    "        kv[\"graphic_size\"] = \"none\"\n",
    "\n",
    "    return \",\".join([f\"{k}={kv[k]}\" for k in TOK_KEYS])\n",
    "\n",
    "def tokens_to_combined_text(tokens_csv: str, category: str, type_: str) -> str:\n",
    "    parts = [p.strip() for p in tokens_csv.split(\",\")]\n",
    "    fixed = []\n",
    "    for i, tok in enumerate(parts):\n",
    "        if \"=\" in tok: fixed.append(tok)\n",
    "        else: fixed.append(f\"{TOK_KEYS[i]}={tok}\")\n",
    "    return f\"category={category} | type={type_} | \" + \" | \".join(fixed)\n",
    "\n",
    "# ================== GPT 호출 ==================\n",
    "async def tag_one(image_path: str) -> Tuple[str, str]:\n",
    "    b64, mime = image_to_b64(image_path)\n",
    "    messages = [{\n",
    "        \"role\":\"user\",\n",
    "        \"content\":[\n",
    "            {\"type\":\"text\",\"text\":PROMPT},\n",
    "            {\"type\":\"image_url\",\"image_url\":{\"url\":f\"data:{mime};base64,{b64}\"}}\n",
    "        ]\n",
    "    }]\n",
    "    resp = await aclient.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=160,\n",
    "        temperature=0.0,\n",
    "        top_p=1.0,\n",
    "        seed=12345,\n",
    "    )\n",
    "    text = resp.choices[0].message.content.strip()\n",
    "    return image_path, normalize_caption_18(text)\n",
    "\n",
    "async def run_stage1(image_paths: List[str], pid2cat: Dict[str, Tuple[str,str]]) -> pd.DataFrame:\n",
    "    sem = asyncio.Semaphore(MAX_CONCURRENCY)\n",
    "    out = []\n",
    "    done = 0\n",
    "\n",
    "    async def worker(p):\n",
    "        async with sem:\n",
    "            try:\n",
    "                _, cap18 = await tag_one(p)\n",
    "            except Exception as e:\n",
    "                print(\"caption error:\", p, e)\n",
    "                cap18 = \",\".join([f\"{k}=unknown\" for k in TOK_KEYS])\n",
    "            pid = extract_product_id_from_filename(p)\n",
    "            major, sub = pid2cat.get(pid, (\"상의\",\"\"))\n",
    "            cat_en, type_en = map_categories_and_sub(major, sub)\n",
    "            combined = tokens_to_combined_text(cap18, cat_en, type_en)\n",
    "            return {\"product_id\": pid, \"combined_text\": combined}\n",
    "\n",
    "    tasks = [asyncio.create_task(worker(p)) for p in image_paths]\n",
    "\n",
    "    for fut in asyncio.as_completed(tasks):\n",
    "        row = await fut\n",
    "        out.append(row)\n",
    "        done += 1\n",
    "        if done % 10 == 0 or done == len(tasks):\n",
    "            df_partial = pd.DataFrame(out).drop_duplicates(\"product_id\")\n",
    "            df_partial.to_csv(OUT_CSV, index=False, encoding=\"utf-8\")\n",
    "            print(f\"[Stage1] {done}/{len(tasks)} saved → {OUT_CSV}\")\n",
    "\n",
    "    return pd.DataFrame(out).drop_duplicates(\"product_id\")\n",
    "\n",
    "# ================== 실행 ==================\n",
    "exts = (\".jpg\",\".jpeg\",\".png\",\".webp\",\".bmp\",\".jfif\")\n",
    "image_paths = [\n",
    "    os.path.join(IMAGE_DIR,f)\n",
    "    for f in os.listdir(IMAGE_DIR)\n",
    "    if f.lower().endswith(exts) and f.lower().startswith(\"top_\")\n",
    "]\n",
    "if len(image_paths) == 0:\n",
    "    raise RuntimeError(\"처리할 top 이미지가 없습니다.\")\n",
    "\n",
    "pid2cat = load_top_map(PRODUCT_INFO_CSV)\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "df = await run_stage1(image_paths, pid2cat)\n",
    "df.to_csv(OUT_CSV, index=False, encoding=\"utf-8\")\n",
    "print(\"✅ 저장 완료:\", OUT_CSV)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb149a2",
   "metadata": {},
   "source": [
    "## pants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe6dcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Stage 1: 이미지 → GPT-4o-mini 태깅 → combined_text 생성 → CSV 저장\n",
    "# - 결과 CSV: pants_caption.csv  (columns: product_id, combined_text)\n",
    "# - category/type은 원본 CSV(pants.csv)에서 조회\n",
    "# - pants (하의)만 처리\n",
    "\n",
    "import os, re, io, base64, asyncio\n",
    "from typing import List, Dict, Tuple\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "# ================== 경로/환경 ==================\n",
    "IMAGE_DIR = \"crop_0.5\"          # crop 이미지 폴더 (파일명: pants_상품코드.ext / jeans_ / shorts_ 등)\n",
    "PRODUCT_INFO_CSV = \"29cm_1000.csv\"  # [상품코드, 대분류, 소분류]\n",
    "OUT_CSV = \"pants_caption.csv\"   # 최종 산출물\n",
    "\n",
    "MAX_SIDE = 768\n",
    "JPEG_QUALITY = 85\n",
    "MAX_CONCURRENCY = 4\n",
    "\n",
    "load_dotenv()\n",
    "aclient = AsyncOpenAI()  # OPENAI_API_KEY 필요\n",
    "\n",
    "# ================== 토큰 키 (PANTS 16개) ==================\n",
    "TOK_KEYS = [\n",
    "    \"fit\",\"rise\",\"waistband\",\"closure\",\"cuffs\",\"front.structure\",\n",
    "    \"pockets.style\",\"pockets.secure\",\"material.fabric\",\"denim.wash\",\n",
    "    \"pattern\",\"pattern_scale\",\"color.main\",\"color.sub\",\"leg.length\",\"hem.opening\"\n",
    "]\n",
    "\n",
    "# ================== 허용값/별칭 ==================\n",
    "ALLOWED_PATTERN = {\n",
    "    \"solid\",\"stripe\",\"check\",\"houndstooth\",\"herringbone\",\"dot\",\"floral\",\"paisley\",\n",
    "    \"animal\",\"camouflage\",\"text\",\"scenic\",\"logo\",\"geometric\",\"abstract\",\"lace-knit\",\"mixed\",\"unknown\"\n",
    "}\n",
    "PATTERN_ALIASES = {\n",
    "    \"newspaper\":\"text\",\"typographic\":\"text\",\"letters\":\"text\",\"letter\":\"text\",\"textual\":\"text\",\"script\":\"text\",\"font\":\"text\",\n",
    "    \"city\":\"scenic\",\"building\":\"scenic\",\"buildings\":\"scenic\",\"map\":\"scenic\",\"landmark\":\"scenic\",\"architecture\":\"scenic\",\n",
    "    \"chevron\":\"herringbone\",\n",
    "    \"animal print\":\"animal\",\"leopard\":\"animal\",\"zebra\":\"animal\",\"snake\":\"animal\",\"giraffe\":\"animal\",\"cow\":\"animal\",\"tiger\":\"animal\",\n",
    "    \"camo\":\"camouflage\",\"military\":\"camouflage\",\n",
    "    \"monogram\":\"logo\"\n",
    "}\n",
    "ALLOWED_PATSCALE = {\"small\",\"medium\",\"large\",\"none\",\"unknown\"}\n",
    "ALLOWED_COLOR = {\"black\",\"white\",\"gray\",\"beige\",\"cream\",\"brown\",\"navy\",\"blue\",\"green\",\"yellow\",\"orange\",\"red\",\"pink\",\"purple\",\"unknown\"}\n",
    "\n",
    "ALLOWED_FIT = {\"skinny\",\"slim\",\"straight\",\"tapered\",\"wide\",\"relaxed\",\"bootcut\",\"flared\",\"loose\",\"unknown\"}\n",
    "ALLOWED_RISE = {\"low\",\"mid\",\"high\",\"unknown\"}\n",
    "ALLOWED_WAISTBAND = {\"fixed\",\"elastic\",\"drawstring\",\"elastic+drawstring\",\"unknown\"}\n",
    "ALLOWED_CLOSURE = {\"zipper\",\"buttons\",\"drawstring\",\"none\",\"unknown\"}\n",
    "ALLOWED_CUFFS = {\"none\",\"elastic\",\"rib\",\"rolled\",\"raw\",\"zipped\",\"unknown\"}\n",
    "ALLOWED_FRONT = {\"flat-front\",\"pleated-single\",\"pleated-double\",\"darts-only\",\"unknown\"}\n",
    "ALLOWED_POCKET_STYLE = {\"5-pocket\",\"slant\",\"welt\",\"patch\",\"cargo\",\"zip\",\"none\",\"unknown\"}\n",
    "ALLOWED_POCKET_SECURE = {\"none\",\"button\",\"zip\",\"flap\",\"mixed\",\"unknown\"}\n",
    "ALLOWED_FABRIC = {\"denim\",\"jersey\",\"fleece\",\"woven-cotton\",\"twill\",\"corduroy\",\"woven-poly\",\"nylon\",\"ripstop\",\"wool-blend\",\"leather\",\"satin\",\"other\",\"unknown\"}\n",
    "ALLOWED_DENIM_WASH = {\"raw\",\"dark-wash\",\"mid-wash\",\"light-wash\",\"acid-wash\",\"stone-wash\",\"bleach\",\"coated\",\"colored\",\"whiskered-faded\",\"distressed\",\"clean\",\"none\",\"unknown\"}\n",
    "ALLOWED_LENGTH = {\"shorts\",\"cropped\",\"ankle\",\"full\",\"unknown\"}\n",
    "ALLOWED_HEMOPEN = {\"narrow\",\"regular\",\"wide\",\"unknown\"}\n",
    "\n",
    "def _normalize_pattern_value(p: str) -> str:\n",
    "    p = (p or \"\").strip().lower()\n",
    "    p = PATTERN_ALIASES.get(p, p)\n",
    "    return p if p in ALLOWED_PATTERN else \"unknown\"\n",
    "\n",
    "def _nz(s: str) -> str:\n",
    "    return (s or \"\").strip().lower()\n",
    "\n",
    "# ================== GPT 프롬프트 (바지 16토큰) ==================\n",
    "PROMPT = \"\"\"\n",
    "You are a fashion vision tagger for fashion product retrieval.\n",
    "Analyze ONLY the pants region even if other items/body parts are visible.\n",
    "Never infer hidden details; if not clearly visible, output \"unknown\".\n",
    "If not applicable, output \"none\".\n",
    "Ignore tops, footwear, accessories, or background items. Only describe the pants themselves.\n",
    "IMPORTANT: Do NOT output product category (e.g., denim/jogger/slacks/…). These are provided externally.\n",
    "\n",
    "OUTPUT\n",
    "Return ONE line with EXACTLY 16 lowercase, comma-separated tokens as key=value pairs,\n",
    "using these keys IN THIS ORDER (keys must match exactly; no extra fields):\n",
    "\n",
    "1) fit\n",
    "   skinny / slim / straight / tapered / wide / relaxed / bootcut / flared / loose / unknown\n",
    "2) rise\n",
    "   low / mid / high / unknown\n",
    "3) waistband\n",
    "   fixed / elastic / drawstring / elastic+drawstring / unknown\n",
    "4) closure\n",
    "   zipper / buttons / drawstring / none / unknown\n",
    "5) cuffs\n",
    "   none / elastic / rib / rolled / raw / zipped / unknown\n",
    "6) front.structure\n",
    "   flat-front / pleated-single / pleated-double / darts-only / unknown\n",
    "7) pockets.style\n",
    "   5-pocket / slant / welt / patch / cargo / zip / none / unknown\n",
    "8) pockets.secure\n",
    "   none / button / zip / flap / mixed / unknown\n",
    "9) material.fabric\n",
    "   denim / jersey / fleece / woven-cotton / twill / corduroy / woven-poly / nylon / ripstop / wool-blend / leather / satin / other / unknown\n",
    "10) denim.wash\n",
    "   raw / dark-wash / mid-wash / light-wash / acid-wash / stone-wash / bleach / coated / colored / whiskered-faded / distressed / clean / none / unknown\n",
    "   (if material.fabric ≠ denim ⇒ set to \"none\")\n",
    "11) pattern\n",
    "   solid / stripe / check / houndstooth / herringbone / dot / floral / paisley / animal / camouflage / text / scenic / logo / geometric / abstract / lace-knit / mixed / unknown\n",
    "12) pattern_scale\n",
    "   small / medium / large / none / unknown (if pattern=solid ⇒ none)\n",
    "13) color.main\n",
    "   black / white / gray / beige / cream / brown / navy / blue / green / yellow / orange / red / pink / purple / unknown\n",
    "14) color.sub\n",
    "   second-most color on the pants (≥15% of pant area) else none\n",
    "15) leg.length\n",
    "   shorts / cropped / ankle / full / unknown\n",
    "16) hem.opening\n",
    "   narrow / regular / wide / unknown\n",
    "\n",
    "---\n",
    "\n",
    "SELECTION GUIDELINES\n",
    "- fit: overall leg silhouette (tapered narrows to hem; straight stays constant; relaxed/loose is roomy; bootcut/flared widens from knee).\n",
    "- rise: relative to natural waist (low <, high >; else mid). If covered by tops ⇒ unknown.\n",
    "- waistband vs closure:\n",
    "  elastic / elastic+drawstring ⇒ gathered stretch; drawstring shows a visible cord.\n",
    "  fixed waist ⇒ usually zipper or buttons; if only a cord is visible ⇒ closure=drawstring.\n",
    "- cuffs: rib/elastic bands ⇒ jogger-like; rolled = turn-ups; raw = cut-off fray; zipped = hem zippers.\n",
    "- front.structure: flat-front (no pleats), pleated-single/double, darts-only (no visible pleats).\n",
    "- pockets.style: 5-pocket (jeans layout), slant (chino/slacks), welt (back slit with welts), patch (sewn-on), cargo (large thigh), zip (visible zipper pockets).\n",
    "  If multiple are equally present, prefer cargo > 5-pocket > slant > welt > patch > zip.\n",
    "- material.fabric: pick the dominant cloth; coated denim is still denim (mark coating under denim.wash).\n",
    "- denim.wash (DENIM ONLY): raw, dark-/mid-/light-wash; acid-/stone-/bleach; coated/colored; whiskered-faded; distressed; clean. If not denim ⇒ none.\n",
    "- pattern vs wash: whiskers/fades/distressing are denim.wash, NOT pattern. pattern is prints/weaves (check, camo, stripe, etc.).\n",
    "- pattern_scale: small < ~1/20; medium ~1/20–1/6; large > ~1/6 of visible leg height.\n",
    "- colors: measure on pant area only (ignore belt/background/shoes).\n",
    "- leg.length: shorts above knee; cropped noticeably above ankle; ankle around ankle bone; full covers ankle.\n",
    "- hem.opening: the openness at hem relative to knee/thigh. flared/bootcut ⇒ typically wide; skinny/tapered ⇒ typically narrow.\n",
    "- A small single brand logo patch/embroidery does not count as a pattern; keep pattern=solid unless logos repeat across the fabric.\n",
    "\n",
    "---\n",
    "\n",
    "CONSISTENCY RULES\n",
    "- waistband ∈ {elastic, elastic+drawstring} without a fixed band ⇒ closure should be drawstring or none (avoid zipper/buttons unless clearly visible).\n",
    "- if pattern=solid ⇒ pattern_scale=none (enforce).\n",
    "- if material.fabric ≠ denim ⇒ denim.wash=none (enforce).\n",
    "- fit vs hem.opening: if fit ∈ {flared, bootcut} and hem.opening is unknown ⇒ set hem.opening=wide. If fit ∈ {skinny, slim, tapered} and hem.opening is unknown ⇒ set hem.opening=narrow.\n",
    "- cuffs ∈ {elastic, rib, zipped} with unknown hem.opening ⇒ prefer hem.opening=narrow.\n",
    "- when attributes conflict and you cannot resolve, set the conflicting token(s) to \"unknown\".\n",
    "\n",
    "---\n",
    "\n",
    "PATTERN DISAMBIGUATION PRIORITY\n",
    "animal > (stripe | check) > camouflage > logo > text > scenic\n",
    "> (houndstooth | herringbone) > (floral | paisley) > (geometric | abstract) > lace-knit > solid.\n",
    "\n",
    "---\n",
    "\n",
    "FORMAT RULES\n",
    "- Exactly 16 tokens, lowercase, comma-separated\n",
    "- If <70% certain ⇒ unknown; if truly absent ⇒ none.\n",
    "- Each token must be key=value\n",
    "- No extra words, no explanations\n",
    "- Example valid output:\n",
    "  \"fit=slim,rise=mid,waistband=fixed,closure=zipper,cuffs=none,front.structure=flat-front,pockets.style=5-pocket,pockets.secure=none,material.fabric=denim,denim.wash=mid-wash,pattern=solid,pattern_scale=none,color.main=blue,color.sub=none,leg.length=full,hem.opening=regular\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ================== 도우미 함수 ==================\n",
    "def image_to_b64(image_path: str, max_side: int = MAX_SIDE, jpeg_quality: int = JPEG_QUALITY):\n",
    "    im = Image.open(image_path).convert(\"RGB\")\n",
    "    w, h = im.size\n",
    "    scale = max(w, h) / float(max_side)\n",
    "    if scale > 1.0:\n",
    "        try: resample = Image.Resampling.BICUBIC\n",
    "        except AttributeError: resample = Image.BICUBIC\n",
    "        im = im.resize((int(w/scale), int(h/scale)), resample)\n",
    "    buf = io.BytesIO()\n",
    "    im.save(buf, format=\"JPEG\", quality=jpeg_quality, optimize=True)\n",
    "    return base64.b64encode(buf.getvalue()).decode(\"utf-8\"), \"image/jpeg\"\n",
    "\n",
    "# 파일명에서 product_id 추출 — pants/jeans/shorts 접두 허용\n",
    "PID_FROM_NAME = re.compile(r\"^(?:pants|jeans|shorts)_([^.\\\\/]+)\", re.IGNORECASE)\n",
    "def extract_product_id_from_filename(path: str) -> str:\n",
    "    base = os.path.basename(path)\n",
    "    m = PID_FROM_NAME.search(base)\n",
    "    return (m.group(1) if m else \"\").strip().lower()\n",
    "\n",
    "# 제품 CSV 불러오기 (하의만)\n",
    "def load_pants_map(csv_path: str) -> Dict[str, Tuple[str,str]]:\n",
    "    df = pd.read_csv(csv_path, dtype=str)\n",
    "    df = df.fillna(\"\").apply(lambda col: col.str.strip().str.lower())\n",
    "    # 대분류가 '하의' 또는 '바지'인 것만 사용\n",
    "    df_pants = df[df[\"대분류\"].isin([\"하의\",\"바지\"])]\n",
    "    return dict(zip(df_pants[\"상품코드\"], zip(df_pants[\"대분류\"], df_pants[\"소분류\"])))\n",
    "\n",
    "# 카테고리/타입 매핑 (ko → en)\n",
    "def map_categories_and_type(major: str, sub: str) -> Tuple[str, str]:\n",
    "    def norm(x: str) -> str:\n",
    "        return (x or \"\").replace(\" \", \"\").replace(\"/\", \"\").replace(\"-\", \"\").strip().lower()\n",
    "    major_map = {\"하의\":\"pants\",\"바지\":\"pants\"}\n",
    "    sub_map = {\n",
    "        \"데님팬츠\":\"denim-pants\",\n",
    "        \"트레이닝조거팬츠\":\"jogger-pants\",\n",
    "        \"코튼팬츠\":\"cotton-pants\",\n",
    "        \"슈트팬츠슬랙스\":\"slacks\",\n",
    "        \"슈트슬랙스\":\"slacks\",\n",
    "        \"숏팬츠\":\"short-pants\",\n",
    "        \"레깅스\":\"leggings\",\n",
    "        \"카고팬츠\":\"cargo-pants\",\n",
    "    }\n",
    "    major_en = major_map.get(norm(major), \"pants\")\n",
    "    type_en  = sub_map.get(norm(sub), \"unknown\")\n",
    "    return major_en, type_en\n",
    "\n",
    "# 캡션 정규화 (16토큰 값만 정규화; key=가 포함돼도 안전)\n",
    "def normalize_caption_pants16(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    text = \" \".join(text.splitlines()).strip().strip('\"').strip(\"'\")\n",
    "    parts = [p.strip().lower() for p in text.split(\",\") if p]\n",
    "\n",
    "    # key=value가 들어왔으면 값만 추출\n",
    "    vals = []\n",
    "    for i, p in enumerate(parts):\n",
    "        if \"=\" in p:\n",
    "            k, v = p.split(\"=\", 1)\n",
    "            vals.append(v.strip())\n",
    "        else:\n",
    "            vals.append(p)\n",
    "\n",
    "    # 패딩/트림\n",
    "    if len(vals) < 16:\n",
    "        vals += [\"unknown\"] * (16 - len(vals))\n",
    "    elif len(vals) > 16:\n",
    "        vals = vals[:16]\n",
    "\n",
    "    # 인덱스\n",
    "    i_fit, i_rise, i_waist, i_closure, i_cuffs, i_front = 0,1,2,3,4,5\n",
    "    i_pstyle, i_psecure = 6,7\n",
    "    i_fabric, i_wash = 8,9\n",
    "    i_pat, i_pscale = 10,11\n",
    "    i_cmain, i_csub = 12,13\n",
    "    i_len, i_hem = 14,15\n",
    "\n",
    "    def _in(x, allowed): return x if x in allowed else \"unknown\"\n",
    "\n",
    "    vals[i_fit]     = _in(vals[i_fit], ALLOWED_FIT)\n",
    "    vals[i_rise]    = _in(vals[i_rise], ALLOWED_RISE)\n",
    "    vals[i_waist]   = _in(vals[i_waist], ALLOWED_WAISTBAND)\n",
    "    vals[i_closure] = _in(vals[i_closure], ALLOWED_CLOSURE)\n",
    "    vals[i_cuffs]   = _in(vals[i_cuffs], ALLOWED_CUFFS)\n",
    "    vals[i_front]   = _in(vals[i_front], ALLOWED_FRONT)\n",
    "    vals[i_pstyle]  = _in(vals[i_pstyle], ALLOWED_POCKET_STYLE)\n",
    "    vals[i_psecure] = _in(vals[i_psecure], ALLOWED_POCKET_SECURE)\n",
    "    vals[i_fabric]  = _in(vals[i_fabric], ALLOWED_FABRIC)\n",
    "\n",
    "    # denim.wash\n",
    "    wash = _nz(vals[i_wash])\n",
    "    if vals[i_fabric] != \"denim\":\n",
    "        wash = \"none\"\n",
    "    elif wash not in ALLOWED_DENIM_WASH:\n",
    "        wash = \"unknown\"\n",
    "    vals[i_wash] = wash\n",
    "\n",
    "    # 패턴/스케일\n",
    "    pattern = _normalize_pattern_value(vals[i_pat])\n",
    "    vals[i_pat] = pattern\n",
    "    pscale = _nz(vals[i_pscale])\n",
    "    if pattern == \"solid\":\n",
    "        pscale = \"none\"\n",
    "    elif pscale not in ALLOWED_PATSCALE:\n",
    "        pscale = \"unknown\"\n",
    "    vals[i_pscale] = pscale\n",
    "\n",
    "    # 색상\n",
    "    vals[i_cmain] = _in(vals[i_cmain], ALLOWED_COLOR)\n",
    "    csub = _nz(vals[i_csub])\n",
    "    vals[i_csub] = csub if (csub in ALLOWED_COLOR or csub == \"none\") else \"unknown\"\n",
    "\n",
    "    # 길이/밑단\n",
    "    vals[i_len] = _in(vals[i_len], ALLOWED_LENGTH)\n",
    "    vals[i_hem] = _in(vals[i_hem], ALLOWED_HEMOPEN)\n",
    "\n",
    "    # 일관성 보정\n",
    "    if vals[i_waist] in {\"elastic\",\"elastic+drawstring\"} and vals[i_closure] in {\"zipper\",\"buttons\"}:\n",
    "        vals[i_closure] = \"unknown\"\n",
    "    if vals[i_hem] == \"unknown\":\n",
    "        if vals[i_fit] in {\"flared\",\"bootcut\"}: vals[i_hem] = \"wide\"\n",
    "        elif vals[i_fit] in {\"skinny\",\"slim\",\"tapered\"}: vals[i_hem] = \"narrow\"\n",
    "    if vals[i_hem] == \"unknown\" and vals[i_cuffs] in {\"elastic\",\"rib\",\"zipped\"}:\n",
    "        vals[i_hem] = \"narrow\"\n",
    "\n",
    "    return \",\".join(vals)\n",
    "\n",
    "\n",
    "# ================== GPT 호출 ==================\n",
    "async def tag_one(image_path: str) -> Tuple[str, str]:\n",
    "    b64, mime = image_to_b64(image_path)\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": PROMPT},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:{mime};base64,{b64}\"}}\n",
    "        ]\n",
    "    }]\n",
    "    resp = await aclient.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=160,\n",
    "        temperature=0.0,\n",
    "        top_p=1.0,\n",
    "        seed=12345,\n",
    "    )\n",
    "    text = resp.choices[0].message.content.strip()\n",
    "    return image_path, normalize_caption_pants16(text)\n",
    "\n",
    "async def run_stage1(image_paths: List[str], pid2cat: Dict[str, Tuple[str,str]]) -> pd.DataFrame:\n",
    "    sem = asyncio.Semaphore(MAX_CONCURRENCY)\n",
    "    out = []\n",
    "    done = 0\n",
    "\n",
    "    async def worker(p):\n",
    "        async with sem:\n",
    "            try:\n",
    "                _, cap16 = await tag_one(p)\n",
    "            except Exception as e:\n",
    "                print(\"caption error:\", p, e)\n",
    "                cap16 = \",\".join([f\"{k}=unknown\" for k in TOK_KEYS])\n",
    "            pid = extract_product_id_from_filename(p)\n",
    "            major, sub = pid2cat.get(pid, (\"하의\", \"\"))  # pants만\n",
    "            cat_en, type_en = map_categories_and_type(major, sub)\n",
    "            combined = tokens_to_combined_text(cap16, cat_en, type_en)\n",
    "            return {\"product_id\": pid, \"combined_text\": combined}\n",
    "\n",
    "    tasks = [asyncio.create_task(worker(p)) for p in image_paths]\n",
    "\n",
    "    for fut in asyncio.as_completed(tasks):\n",
    "        row = await fut\n",
    "        out.append(row)\n",
    "        done += 1\n",
    "\n",
    "        # 🔹 10개마다 중간 저장 (덮어쓰기)\n",
    "        if done % 10 == 0 or done == len(tasks):\n",
    "            df_partial = pd.DataFrame(out).drop_duplicates(subset=[\"product_id\"], keep=\"first\")\n",
    "            df_partial.to_csv(OUT_CSV, index=False, encoding=\"utf-8\")\n",
    "            print(f\"[Stage1] {done}/{len(tasks)} saved → {OUT_CSV}\")\n",
    "\n",
    "    # 마지막에 최종 DataFrame 반환\n",
    "    return pd.DataFrame(out).drop_duplicates(subset=[\"product_id\"], keep=\"first\")\n",
    "\n",
    "# ================== 실행 ==================\n",
    "# pants_* / jeans_* / shorts_* 이미지만 추출\n",
    "exts = (\".jpg\",\".jpeg\",\".png\",\".webp\",\".bmp\",\".jfif\")\n",
    "image_paths = [\n",
    "    os.path.join(IMAGE_DIR, f)\n",
    "    for f in os.listdir(IMAGE_DIR)\n",
    "    if f.lower().endswith(exts) and (f.lower().startswith(\"pants_\") or f.lower().startswith(\"jeans_\") or f.lower().startswith(\"shorts_\"))\n",
    "]\n",
    "if len(image_paths) == 0:\n",
    "    raise RuntimeError(\"처리할 pants/jeans/shorts 이미지가 없습니다.\")\n",
    "\n",
    "pid2cat = load_pants_map(PRODUCT_INFO_CSV)\n",
    "\n",
    "# 🔹 Jupyter에서는 asyncio.run() 대신 await 사용\n",
    "import nest_asyncio, asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "df = await run_stage1(image_paths, pid2cat)   # ✅ 여기서 await로 실행\n",
    "df.to_csv(OUT_CSV, index=False, encoding=\"utf-8\")\n",
    "print(\"✅ 저장 완료:\", OUT_CSV)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d3bd76",
   "metadata": {},
   "source": [
    "## skirt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf60f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Stage 1: 이미지 → GPT-4o-mini 태깅 → combined_text 생성 → CSV 저장\n",
    "# - 결과 CSV: skirt_caption.csv  (columns: product_id, combined_text)\n",
    "# - category/type은 원본 CSV(skirt.csv)에서 조회\n",
    "# - skirt (스커트)만 처리\n",
    "\n",
    "import os, re, io, base64, asyncio\n",
    "from typing import List, Dict, Tuple\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "# ================== 경로/환경 ==================\n",
    "IMAGE_DIR = \"crop_29cm\"\n",
    "PRODUCT_INFO_CSV = \"29cm/29cm_1000.csv\"\n",
    "OUT_CSV = \"29cm/skirt_caption.csv\"\n",
    "\n",
    "MAX_SIDE = 768\n",
    "JPEG_QUALITY = 85\n",
    "MAX_CONCURRENCY = 4\n",
    "\n",
    "load_dotenv()\n",
    "aclient = AsyncOpenAI()  # OPENAI_API_KEY 필요\n",
    "\n",
    "# ================== 토큰 키 (15개) ==================\n",
    "TOK_KEYS = [\n",
    "    \"color.main\",\"color.sub\",\"color.tone\",\"pattern\",\"pattern_scale\",\n",
    "    \"material.fabric\",\"silhouette\",\"pleated\",\"flare_level\",\"wrap\",\n",
    "    \"closure\",\"details.pockets\",\"details.slit\",\"details.hem_finish\",\n",
    "    \"style\"\n",
    "]\n",
    "\n",
    "# ================== GPT 프롬프트 ==================\n",
    "PROMPT = \"\"\"\n",
    "You are a vision tagger for fashion product retrieval.\n",
    "Analyze ONLY the skirt region even if other items/body parts are visible.\n",
    "Never infer hidden details.  \n",
    "If an attribute is not clearly visible:\n",
    "- For closure, details.pockets, details.slit: output \"none\"\n",
    "- For all other attributes: output \"unknown\"\n",
    "\n",
    "If the attribute truly does not exist, output \"none\".  \n",
    "Ignore hands, legs, accessories, or background items. Only describe the skirt itself.\n",
    "\n",
    "Return ONE line with EXACTLY 15 lowercase, comma-separated tokens as key=value pairs,\n",
    "using these keys IN THIS ORDER (keys must match exactly; no extra fields):\n",
    "\n",
    "1) color.main\n",
    "   black / white / gray / beige / cream / brown / navy / blue / green / yellow / orange / red / pink / purple / unknown\n",
    "2) color.sub\n",
    "   second-most visible (≥15% of skirt area) else none\n",
    "3) color.tone\n",
    "   light / mid / dark / unknown\n",
    "4) pattern\n",
    "   solid / stripe / check / houndstooth / herringbone / dot / floral / paisley / animal / camouflage / text / scenic / logo / geometric / abstract / lace-knit / mixed / unknown\n",
    "5) pattern_scale\n",
    "   small / medium / large / none / unknown (if pattern=solid ⇒ none)\n",
    "6) material.fabric\n",
    "   knit / denim / leather / suede / corduroy / chiffon / satin / lace / tweed / wool-blend / woven-cotton / woven-poly / tulle / other / unknown\n",
    "7) silhouette\n",
    "   a-line / h-line / pencil / trumpet / mermaid / pleated / tulip / bubble / asymmetric / wrap / layered / gypsy / tiered / prairie / flounced / bias / draped / peplum / pant-skirt / slit / sarong / other / unknown\n",
    "8) pleated\n",
    "   yes / no / unknown\n",
    "9) flare_level\n",
    "   low / medium / high / none / unknown\n",
    "10) wrap\n",
    "   yes / no / unknown\n",
    "11) closure\n",
    "   zipper / buttons / hooks / drawstring / none / unknown\n",
    "12) details.pockets\n",
    "   cargo / welt / patch / none / unknown\n",
    "13) details.slit\n",
    "   front / side / back / none / unknown\n",
    "14) details.hem_finish\n",
    "   cutoff / clean / uneven / rolled / raw / unknown\n",
    "15) style\n",
    "   casual / formal / office / evening / street / school / sporty / unknown\n",
    "\n",
    "---\n",
    "\n",
    "CONSISTENCY RULES\n",
    "- if pattern=solid ⇒ pattern_scale=none\n",
    "- if silhouette=pleated ⇒ pleated=yes\n",
    "- if pleated=yes but silhouette≠pleated ⇒ silhouette must not be \"unknown\"\n",
    "- if wrap=yes ⇒ closure=none\n",
    "\n",
    "---\n",
    "\n",
    "FORMAT RULES\n",
    "- Exactly 15 tokens, lowercase, comma-separated\n",
    "- key=value for every token\n",
    "- No extra words, no explanations\n",
    "- Example valid output:\n",
    "  \"color.main=black,color.sub=none,color.tone=dark,pattern=solid,pattern_scale=none,material.fabric=chiffon,silhouette=pleated,pleated=yes,flare_level=high,wrap=no,closure=zipper,details.pockets=none,details.slit=side,details.hem_finish=clean,style=casual\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ================== normalize (A 코드 그대로 유지) ==================\n",
    "def normalize_caption_15(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    text = \" \".join(text.splitlines()).strip().strip('\"').strip(\"'\")\n",
    "    parts = [p.strip().lower() for p in text.split(\",\") if p]\n",
    "    if len(parts) < 15:\n",
    "        parts += [\"unknown\"] * (15 - len(parts))\n",
    "    elif len(parts) > 15:\n",
    "        parts = parts[:15]\n",
    "\n",
    "    i = {name: idx for idx, name in enumerate(TOK_KEYS)}\n",
    "\n",
    "    if parts[i[\"pattern\"]] == \"solid\":\n",
    "        parts[i[\"pattern_scale\"]] = \"none\"\n",
    "    if parts[i[\"pleated\"]] not in (\"yes\",\"no\",\"unknown\"):\n",
    "        parts[i[\"pleated\"]] = \"unknown\"\n",
    "    if parts[i[\"wrap\"]] not in (\"yes\",\"no\",\"unknown\"):\n",
    "        parts[i[\"wrap\"]] = \"unknown\"\n",
    "    if parts[i[\"flare_level\"]] not in (\"low\",\"medium\",\"high\",\"none\",\"unknown\"):\n",
    "        parts[i[\"flare_level\"]] = \"unknown\"\n",
    "    if parts[i[\"details.slit\"]] not in (\"front\",\"side\",\"back\",\"none\",\"unknown\"):\n",
    "        parts[i[\"details.slit\"]] = \"unknown\"\n",
    "    if parts[i[\"details.hem_finish\"]] not in (\"cutoff\",\"clean\",\"uneven\",\"rolled\",\"raw\",\"unknown\"):\n",
    "        parts[i[\"details.hem_finish\"]] = \"unknown\"\n",
    "    if parts[i[\"silhouette\"]] == \"pleated\":\n",
    "        parts[i[\"pleated\"]] = \"yes\"\n",
    "    if parts[i[\"wrap\"]] == \"yes\":\n",
    "        parts[i[\"closure\"]] = \"none\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return \",\".join(parts)\n",
    "\n",
    "def tokens_to_combined_text(tokens_csv: str, category: str, type_: str) -> str:\n",
    "    parts = [p.strip() for p in tokens_csv.split(\",\")]\n",
    "    fixed = []\n",
    "    for i, tok in enumerate(parts):\n",
    "        if \"=\" in tok:\n",
    "            fixed.append(tok)\n",
    "        else:\n",
    "            fixed.append(f\"{TOK_KEYS[i]}={tok}\")\n",
    "    return f\"category={category} | type={type_} | \" + \" | \".join(fixed)\n",
    "\n",
    "# ================== 제품 CSV 매핑 ==================\n",
    "def load_category_map_fixed(csv_path: str) -> Dict[str, Tuple[str, str]]:\n",
    "    df = pd.read_csv(csv_path, dtype=str).fillna(\"\").apply(lambda col: col.str.strip().str.lower())\n",
    "    df_skirt = df[df[\"대분류\"] == \"스커트\"]\n",
    "    return dict(zip(df_skirt[\"상품코드\"], zip(df_skirt[\"대분류\"], df_skirt[\"소분류\"])))\n",
    "\n",
    "PID_RE = re.compile(r\"^skirt_([^.\\\\/]+)\", re.IGNORECASE)\n",
    "def extract_product_id_from_filename(path: str) -> str:\n",
    "    base = os.path.basename(path)\n",
    "    m = PID_RE.search(base)\n",
    "    return (m.group(1) if m else \"\").strip().lower()\n",
    "\n",
    "def map_categories_and_sub(major: str, sub: str) -> Tuple[str, str]:\n",
    "    major_map = {\"스커트\": \"skirt\"}\n",
    "    sub_map = {\"미니스커트\":\"miniskirt\",\"미디스커트\":\"midiskirt\",\"롱스커트\":\"longskirt\"}\n",
    "    return major_map.get(major, \"skirt\"), sub_map.get(sub, \"unknown\")\n",
    "\n",
    "# ================== GPT 호출 ==================\n",
    "def image_to_b64(image_path: str, max_side: int = MAX_SIDE, jpeg_quality: int = JPEG_QUALITY):\n",
    "    im = Image.open(image_path).convert(\"RGB\")\n",
    "    w, h = im.size\n",
    "    scale = max(w, h) / float(max_side)\n",
    "    if scale > 1.0:\n",
    "        try: resample = Image.Resampling.BICUBIC\n",
    "        except AttributeError: resample = Image.BICUBIC\n",
    "        im = im.resize((int(w/scale), int(h/scale)), resample)\n",
    "    buf = io.BytesIO()\n",
    "    im.save(buf, format=\"JPEG\", quality=jpeg_quality, optimize=True)\n",
    "    return base64.b64encode(buf.getvalue()).decode(\"utf-8\"), \"image/jpeg\"\n",
    "\n",
    "async def tag_one(image_path: str) -> Tuple[str, str]:\n",
    "    b64, mime = image_to_b64(image_path)\n",
    "    messages = [{\n",
    "        \"role\":\"user\",\n",
    "        \"content\":[\n",
    "            {\"type\":\"text\",\"text\":PROMPT},\n",
    "            {\"type\":\"image_url\",\"image_url\":{\"url\":f\"data:{mime};base64,{b64}\"}}\n",
    "        ]\n",
    "    }]\n",
    "    resp = await aclient.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=160,\n",
    "        temperature=0.0,\n",
    "        top_p=1.0,\n",
    "        seed=12345,\n",
    "    )\n",
    "    text = resp.choices[0].message.content.strip()\n",
    "    return image_path, normalize_caption_15(text)\n",
    "\n",
    "# ================== Stage1 실행 ==================\n",
    "async def run_stage1(image_paths: List[str], pid2cat: Dict[str, Tuple[str,str]]) -> pd.DataFrame:\n",
    "    sem = asyncio.Semaphore(MAX_CONCURRENCY)\n",
    "    out = []\n",
    "    done = 0\n",
    "\n",
    "    async def worker(p):\n",
    "        async with sem:\n",
    "            try:\n",
    "                _, cap15 = await tag_one(p)\n",
    "            except Exception as e:\n",
    "                print(\"caption error:\", p, e)\n",
    "                cap15 = \",\".join([f\"{k}=unknown\" for k in TOK_KEYS])\n",
    "            pid = extract_product_id_from_filename(p)\n",
    "            major, sub = pid2cat.get(pid, (\"스커트\", \"\"))\n",
    "            cat_en, type_en = map_categories_and_sub(major, sub)\n",
    "            combined = tokens_to_combined_text(cap15, cat_en, type_en)\n",
    "            return {\"product_id\": pid, \"combined_text\": combined}\n",
    "\n",
    "    tasks = [asyncio.create_task(worker(p)) for p in image_paths]\n",
    "\n",
    "    for fut in asyncio.as_completed(tasks):\n",
    "        row = await fut\n",
    "        out.append(row)\n",
    "        done += 1\n",
    "        if done % 10 == 0 or done == len(tasks):\n",
    "            df_partial = pd.DataFrame(out).drop_duplicates(\"product_id\")\n",
    "            df_partial.to_csv(OUT_CSV, index=False, encoding=\"utf-8\")\n",
    "            print(f\"[Stage1] {done}/{len(tasks)} saved → {OUT_CSV}\")\n",
    "\n",
    "    return pd.DataFrame(out).drop_duplicates(\"product_id\")\n",
    "\n",
    "# ================== 실행 ==================\n",
    "exts = (\".jpg\",\".jpeg\",\".png\",\".webp\",\".bmp\",\".jfif\")\n",
    "image_paths = [\n",
    "    os.path.join(IMAGE_DIR,f)\n",
    "    for f in os.listdir(IMAGE_DIR)\n",
    "    if f.lower().endswith(exts) and f.lower().startswith(\"skirt_\")\n",
    "]\n",
    "if len(image_paths) == 0:\n",
    "    raise RuntimeError(\"처리할 skirt 이미지가 없습니다.\")\n",
    "\n",
    "pid2cat = load_category_map_fixed(PRODUCT_INFO_CSV)\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "df = await run_stage1(image_paths, pid2cat)\n",
    "df.to_csv(OUT_CSV, index=False, encoding=\"utf-8\")\n",
    "print(\"✅ 저장 완료:\", OUT_CSV)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badab0e0",
   "metadata": {},
   "source": [
    "## dress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ceb32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Stage 1: 이미지 → GPT-4o-mini 태깅 → combined_text 생성 → CSV 저장\n",
    "# - 결과 CSV: dress_caption.csv  (columns: product_id, combined_text)\n",
    "# - category/type은 원본 CSV(29cm_1000.csv)에서 조회\n",
    "# - dress (원피스)만 처리\n",
    "\n",
    "import os, re, io, base64, asyncio\n",
    "from typing import List, Dict, Tuple\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "# ================== 경로/환경 ==================\n",
    "IMAGE_DIR = \"crop_0.5\"          # crop 이미지 폴더 (파일명: dress_상품코드.ext 등)\n",
    "PRODUCT_INFO_CSV = \"29cm_1000.csv\"  # [상품코드, 대분류, 소분류]\n",
    "OUT_CSV = \"dress_caption.csv\"       # 최종 산출물\n",
    "\n",
    "MAX_SIDE = 768\n",
    "JPEG_QUALITY = 85\n",
    "MAX_CONCURRENCY = 4\n",
    "\n",
    "load_dotenv()\n",
    "aclient = AsyncOpenAI()  # OPENAI_API_KEY 필요\n",
    "\n",
    "# ================== 토큰 키 ==================\n",
    "TOK_KEYS = [\n",
    "    \"bodice.fit\",\"skirt.volume\",\"dress.length\",\"hemline.shape\",\"hem.finish\",\n",
    "    \"waistline\",\"neckline\",\"sleeve.length\",\"sleeve.style\",\"skirt.structure\",\n",
    "    \"pattern\",\"pattern_scale\",\"material.fabric\",\"color.main\",\"color.sub\",\"closure\",\"skirt.slit\"\n",
    "]\n",
    "\n",
    "# ================== 허용값/별칭 ==================\n",
    "ALLOWED_PATTERNS = {\n",
    "    \"solid\",\"stripe\",\"check\",\"houndstooth\",\"herringbone\",\"dot\",\"floral\",\"paisley\",\n",
    "    \"animal\",\"camouflage\",\"text\",\"scenic\",\"logo\",\"geometric\",\"abstract\",\"lace-knit\",\"mixed\",\"unknown\"\n",
    "}\n",
    "PATTERN_ALIASES = {\n",
    "    \"newspaper\":\"text\",\"typographic\":\"text\",\"letters\":\"text\",\"letter\":\"text\",\"textual\":\"text\",\"script\":\"text\",\"font\":\"text\",\n",
    "    \"city\":\"scenic\",\"building\":\"scenic\",\"map\":\"scenic\",\"chevron\":\"herringbone\",\n",
    "    \"animal print\":\"animal\",\"leopard\":\"animal\",\"zebra\":\"animal\",\"snake\":\"animal\",\"tiger\":\"animal\",\"cow\":\"animal\",\n",
    "    \"camo\":\"camouflage\",\"monogram\":\"logo\",\"heather\":\"abstract\",\"marled\":\"abstract\",\"tie-dye\":\"abstract\",\"ikat\":\"abstract\"\n",
    "}\n",
    "ALLOWED_PATSCALE = {\"small\",\"medium\",\"large\",\"none\",\"unknown\"}\n",
    "ALLOWED_COLOR = {\"black\",\"white\",\"gray\",\"beige\",\"cream\",\"brown\",\"navy\",\"blue\",\"green\",\"yellow\",\"orange\",\"red\",\"pink\",\"purple\",\"unknown\"}\n",
    "ALLOWED_HEM_FINISH = {\"clean\",\"rolled\",\"lettuce\",\"scalloped\",\"lace-trim\",\"ruffle-trim\",\"fringed\",\"binding\",\"raw\",\"cutoff\",\"pleated-hem\",\"unknown\"}\n",
    "ALLOWED_SLIT = {\"none\",\"front\",\"side\",\"back\",\"two-side\",\"high-slit\",\"unknown\"}\n",
    "ALLOWED_MATERIAL = {\n",
    "    \"cotton\",\"linen\",\"wool\",\"silk\",\"satin\",\"denim\",\"leather\",\"suede\",\"tweed\",\"knit\",\"rib-knit\",\n",
    "    \"lace\",\"chiffon\",\"tulle\",\"velvet\",\"corduroy\",\"fleece\",\"jersey\",\"terry\",\"seersucker\",\"poplin\",\n",
    "    \"crepe\",\"organza\",\"brocade\",\"jacquard\",\"modal\",\"rayon\",\"viscose\",\"lyocell\",\"tencel\",\n",
    "    \"polyester\",\"nylon\",\"elastane\",\"spandex\",\"acrylic\",\"pu\",\"mesh\",\"eyelet\",\"crochet\",\n",
    "    \"faux-fur\",\"faux-leather\",\"blended\",\"unknown\"\n",
    "}\n",
    "MATERIAL_ALIASES = {\n",
    "    \"poly\":\"polyester\",\"polyamide\":\"nylon\",\"spandex\":\"elastane\",\"elastan\":\"elastane\",\"lycra\":\"elastane\",\n",
    "    \"pleather\":\"faux-leather\",\"fake leather\":\"faux-leather\",\"artificial leather\":\"faux-leather\",\n",
    "    \"tencel™\":\"tencel\",\"viscosa\":\"viscose\",\"modal rayon\":\"modal\",\"cotten\":\"cotton\"\n",
    "}\n",
    "\n",
    "def _normalize_pattern_value(p: str) -> str:\n",
    "    p = (p or \"\").strip().lower()\n",
    "    p = PATTERN_ALIASES.get(p, p)\n",
    "    return p if p in ALLOWED_PATTERNS else \"unknown\"\n",
    "\n",
    "def _nz(s: str) -> str:\n",
    "    return (s or \"\").strip().lower()\n",
    "\n",
    "# ================== GPT 프롬프트 ==================\n",
    "PROMPT = \"\"\"\n",
    "You are a vision tagger for fashion product retrieval.\n",
    "Analyze ONLY the dress (one-piece) region even if other items/body parts are visible.\n",
    "Never infer hidden details; if not clearly visible, output \"unknown\".\n",
    "If not applicable, output \"none\".\n",
    "Ignore hands, legs, accessories, or background items. Only describe the dress itself.\n",
    "\n",
    "Return ONE line with EXACTLY 17 lowercase, comma-separated tokens as key=value pairs,\n",
    "using these keys IN THIS ORDER (keys must match exactly; no extra fields):\n",
    "\n",
    "1) bodice.fit\n",
    "   fitted / semi / relaxed / unknown\n",
    "2) skirt.volume\n",
    "   slim / straight / a-line / full / mermaid / ball-gown / pencil / tulip / unknown\n",
    "3) dress.length\n",
    "   mini / knee / midi / ankle / maxi / unknown\n",
    "4) hemline.shape\n",
    "   straight / high-low / asymmetric / mermaid / ruffled / layered / wrap / train / handkerchief / bubble / shirttail / none / unknown\n",
    "5) hem.finish\n",
    "   clean / rolled / lettuce / scalloped / lace-trim / ruffle-trim / fringed / binding / raw / cutoff / pleated-hem / unknown\n",
    "6) waistline\n",
    "   none / natural / high / empire / drop / unknown\n",
    "7) neckline\n",
    "   round / v / square / halter / collar / off-shoulder / strapless / cowl / keyhole / boat / one-shoulder / unknown\n",
    "8) sleeve.length\n",
    "   sleeveless / cap / short / elbow / three-quarter / long / one-shoulder / strapless / unknown\n",
    "9) sleeve.style\n",
    "   none / puff / balloon / raglan / kimono / off-shoulder / cold-shoulder / bishop / roll-up / unknown\n",
    "10) skirt.structure\n",
    "   none / pleated / gathered / tiered / circle / bias / ruched / wrap / peplum / unknown\n",
    "11) pattern\n",
    "   solid / stripe / check / houndstooth / herringbone / dot / floral / paisley / animal / camouflage / text / scenic / logo / geometric / abstract / lace-knit / mixed / unknown\n",
    "12) pattern_scale\n",
    "   small / medium / large / none / unknown (if pattern=solid ⇒ none)\n",
    "13) material.fabric\n",
    "   cotton / linen / wool / silk / satin / denim / leather / suede / tweed / knit / rib-knit / lace / chiffon / tulle / velvet / corduroy / fleece / jersey / terry / seersucker / poplin / crepe / organza / brocade / jacquard / modal / rayon / viscose / lyocell / tencel / polyester / nylon / elastane / spandex / acrylic / pu / mesh / eyelet / crochet / faux-fur / faux-leather / blended / unknown\n",
    "14) color.main\n",
    "   black / white / gray / beige / cream / brown / navy / blue / green / yellow / orange / red / pink / purple / unknown\n",
    "15) color.sub\n",
    "   second-most ≥ ~15% else none\n",
    "16) closure\n",
    "   zipper / buttons / hooks / drawstring / none / unknown\n",
    "17) skirt.slit\n",
    "   none / front / side / back / two-side / high-slit / unknown\n",
    "\n",
    "---\n",
    "\n",
    "CONSISTENCY\n",
    "- if pattern=solid ⇒ pattern_scale=none.\n",
    "- if sleeve.length=strapless ⇒ neckline=strapless and sleeve.style=none.\n",
    "- if sleeve.length=one-shoulder ⇒ neckline=one-shoulder and sleeve.style=none.\n",
    "- hemline.shape describes the shape; hem.finish describes the finishing/trim; treat them independently.\n",
    "- When unsure, output \"unknown\".\n",
    "\n",
    "---\n",
    "\n",
    "FORMAT RULES\n",
    "- Exactly 17 tokens, lowercase, comma-separated\n",
    "- Each token must be key=value\n",
    "- No extra words, no explanations\n",
    "- Example valid output:\n",
    "  \"bodice.fit=fitted,skirt.volume=a-line,dress.length=midi,hemline.shape=straight,hem.finish=clean,waistline=natural,neckline=round,sleeve.length=short,sleeve.style=none,skirt.structure=pleated,pattern=solid,pattern_scale=none,material.fabric=cotton,color.main=blue,color.sub=none,closure=zipper,skirt.slit=side\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ================== 도우미 함수 ==================\n",
    "def image_to_b64(image_path: str, max_side: int = MAX_SIDE, jpeg_quality: int = JPEG_QUALITY):\n",
    "    im = Image.open(image_path).convert(\"RGB\")\n",
    "    w, h = im.size\n",
    "    scale = max(w, h) / float(max_side)\n",
    "    if scale > 1.0:\n",
    "        try: resample = Image.Resampling.BICUBIC\n",
    "        except AttributeError: resample = Image.BICUBIC\n",
    "        im = im.resize((int(w/scale), int(h/scale)), resample)\n",
    "    buf = io.BytesIO()\n",
    "    im.save(buf, format=\"JPEG\", quality=jpeg_quality, optimize=True)\n",
    "    return base64.b64encode(buf.getvalue()).decode(\"utf-8\"), \"image/jpeg\"\n",
    "\n",
    "# 파일명에서 product_id 추출\n",
    "PID_FROM_NAME = re.compile(r\"^dress_([^.\\\\/]+)\", re.IGNORECASE)\n",
    "def extract_product_id_from_filename(path: str) -> str:\n",
    "    base = os.path.basename(path)\n",
    "    m = PID_FROM_NAME.search(base)\n",
    "    return (m.group(1) if m else \"\").strip().lower()\n",
    "\n",
    "# 제품 CSV 불러오기 (원피스만)\n",
    "def load_dress_map(csv_path: str) -> Dict[str, Tuple[str,str]]:\n",
    "    df = pd.read_csv(csv_path, dtype=str)\n",
    "    df = df.fillna(\"\").apply(lambda col: col.str.strip().str.lower())\n",
    "    df_dress = df[df[\"대분류\"] == \"원피스\"]  # dress만 필터\n",
    "    return dict(zip(df_dress[\"상품코드\"], zip(df_dress[\"대분류\"], df_dress[\"소분류\"])))\n",
    "\n",
    "def map_categories_and_length(major: str, sub: str) -> Tuple[str, str]:\n",
    "    major_map = {\"원피스\":\"dress\"}\n",
    "    sub_map = {\n",
    "        \"미니원피스\":\"minidress\",\n",
    "        \"미디원피스\":\"mididress\",\n",
    "        \"맥시원피스\":\"maxidress\",\n",
    "    }\n",
    "    return major_map.get(major, \"dress\"), sub_map.get(sub, \"unknown\")\n",
    "\n",
    "# 캡션 정규화\n",
    "def normalize_caption_dress17(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    text = \" \".join(text.splitlines()).strip().strip('\"').strip(\"'\")\n",
    "    parts = [p.strip().lower() for p in text.split(\",\") if p]\n",
    "\n",
    "    if len(parts) < 17:\n",
    "        parts += [\"unknown\"] * (17 - len(parts))\n",
    "    elif len(parts) > 17:\n",
    "        parts = parts[:17]\n",
    "\n",
    "    IDX = {k:i for i,k in enumerate(TOK_KEYS)}\n",
    "\n",
    "    # pattern ↔ scale\n",
    "    parts[IDX[\"pattern\"]] = _normalize_pattern_value(parts[IDX[\"pattern\"]])\n",
    "    if parts[IDX[\"pattern\"]] == \"solid\":\n",
    "        parts[IDX[\"pattern_scale\"]] = \"none\"\n",
    "    elif parts[IDX[\"pattern_scale\"]] not in ALLOWED_PATSCALE:\n",
    "        parts[IDX[\"pattern_scale\"]] = \"unknown\"\n",
    "\n",
    "    # 색상\n",
    "    if parts[IDX[\"color.main\"]] not in ALLOWED_COLOR: parts[IDX[\"color.main\"]] = \"unknown\"\n",
    "    if parts[IDX[\"color.sub\"]] not in ALLOWED_COLOR and parts[IDX[\"color.sub\"]] != \"none\":\n",
    "        parts[IDX[\"color.sub\"]] = \"unknown\"\n",
    "\n",
    "    # 소재\n",
    "    mat = MATERIAL_ALIASES.get(_nz(parts[IDX[\"material.fabric\"]]), _nz(parts[IDX[\"material.fabric\"]]))\n",
    "    parts[IDX[\"material.fabric\"]] = mat if mat in ALLOWED_MATERIAL else \"unknown\"\n",
    "\n",
    "    # hem.finish / slit\n",
    "    if parts[IDX[\"hem.finish\"]] not in ALLOWED_HEM_FINISH:\n",
    "        parts[IDX[\"hem.finish\"]] = \"unknown\"\n",
    "    if parts[IDX[\"skirt.slit\"]] not in ALLOWED_SLIT:\n",
    "        parts[IDX[\"skirt.slit\"]] = \"unknown\"\n",
    "\n",
    "    return \",\".join(parts)\n",
    "\n",
    "def tokens_to_combined_text(tokens_csv: str, category: str, type_: str) -> str:\n",
    "    parts = [p.strip() for p in tokens_csv.split(\",\")]\n",
    "    fixed = []\n",
    "    for i, tok in enumerate(parts):\n",
    "        if \"=\" in tok: fixed.append(tok)\n",
    "        else: fixed.append(f\"{TOK_KEYS[i]}={tok}\")\n",
    "    return f\"category={category} | type={type_} | \" + \" | \".join(fixed)\n",
    "\n",
    "# ================== 토큰 → combined_text ==================\n",
    "def tokens_to_combined_text(tokens_csv: str, category: str, type_: str) -> str:\n",
    "    parts = [p.strip() for p in tokens_csv.split(\",\")]\n",
    "    fixed = []\n",
    "    for i, tok in enumerate(parts):\n",
    "        if \"=\" in tok:\n",
    "            fixed.append(tok)\n",
    "        else:\n",
    "            fixed.append(f\"{TOK_KEYS[i]}={tok}\")\n",
    "    return f\"category={category} | type={type_} | \" + \" | \".join(fixed)\n",
    "\n",
    "\n",
    "# ================== GPT 호출 ==================\n",
    "async def tag_one(image_path: str) -> Tuple[str, str]:\n",
    "    b64, mime = image_to_b64(image_path)\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": PROMPT},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:{mime};base64,{b64}\"}}\n",
    "        ]\n",
    "    }]\n",
    "    resp = await aclient.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=160,\n",
    "        temperature=0.0,\n",
    "        top_p=1.0,\n",
    "        seed=12345,\n",
    "    )\n",
    "    text = resp.choices[0].message.content.strip()\n",
    "    return image_path, normalize_caption_dress17(text)\n",
    "\n",
    "async def run_stage1(image_paths: List[str], pid2cat: Dict[str, Tuple[str,str]]) -> pd.DataFrame:\n",
    "    sem = asyncio.Semaphore(MAX_CONCURRENCY)\n",
    "    out = []\n",
    "    done = 0\n",
    "\n",
    "    async def worker(p):\n",
    "        async with sem:\n",
    "            try:\n",
    "                _, cap17 = await tag_one(p)\n",
    "            except Exception as e:\n",
    "                print(\"caption error:\", p, e)\n",
    "                cap17 = \",\".join([f\"{k}=unknown\" for k in TOK_KEYS])\n",
    "            pid = extract_product_id_from_filename(p)\n",
    "            major, sub = pid2cat.get(pid, (\"원피스\", \"\"))  # dress만\n",
    "            cat_en, type_en = map_categories_and_length(major, sub)\n",
    "            combined = tokens_to_combined_text(cap17, cat_en, type_en)\n",
    "            return {\"product_id\": pid, \"combined_text\": combined}\n",
    "\n",
    "    tasks = [asyncio.create_task(worker(p)) for p in image_paths]\n",
    "\n",
    "    for fut in asyncio.as_completed(tasks):\n",
    "        row = await fut\n",
    "        out.append(row)\n",
    "        done += 1\n",
    "\n",
    "        # 🔹 10개마다 중간 저장 (덮어쓰기)\n",
    "        if done % 10 == 0 or done == len(tasks):\n",
    "            df_partial = pd.DataFrame(out).drop_duplicates(subset=[\"product_id\"], keep=\"first\")\n",
    "            df_partial.to_csv(OUT_CSV, index=False, encoding=\"utf-8\")\n",
    "            print(f\"[Stage1] {done}/{len(tasks)} saved → {OUT_CSV}\")\n",
    "\n",
    "    # 마지막에 최종 DataFrame 반환\n",
    "    return pd.DataFrame(out).drop_duplicates(subset=[\"product_id\"], keep=\"first\")\n",
    "\n",
    "\n",
    "\n",
    "# ================== 실행 ==================\n",
    "# dress_* 이미지만 추출\n",
    "exts = (\".jpg\",\".jpeg\",\".png\",\".webp\",\".bmp\",\".jfif\")\n",
    "image_paths = [\n",
    "    os.path.join(IMAGE_DIR, f)\n",
    "    for f in os.listdir(IMAGE_DIR)\n",
    "    if f.lower().endswith(exts) and f.lower().startswith(\"dress_\")\n",
    "]\n",
    "if len(image_paths) == 0:\n",
    "    raise RuntimeError(\"처리할 dress 이미지가 없습니다.\")\n",
    "\n",
    "pid2cat = load_dress_map(PRODUCT_INFO_CSV)\n",
    "\n",
    "# 🔹 Jupyter에서는 asyncio.run() 대신 await 사용\n",
    "import nest_asyncio, asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "df = await run_stage1(image_paths, pid2cat)   # ✅ 여기서 await로 실행\n",
    "df.to_csv(OUT_CSV, index=False, encoding=\"utf-8\")\n",
    "print(\"✅ 저장 완료:\", OUT_CSV)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b10cc68",
   "metadata": {},
   "source": [
    "# caption split : 77 토큰이 넘어 캡션을 두 개로 나누기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ded0c3",
   "metadata": {},
   "source": [
    "## top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be58e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 로드\n",
    "df = pd.read_csv(\"29cm/top_caption.csv\")\n",
    "\n",
    "def split_top_caption(text: str):\n",
    "    \"\"\"top category 속성들을 caption1, caption2로 분리\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\", \"\"\n",
    "\n",
    "    parts = [p.strip() for p in text.split(\"|\")]\n",
    "\n",
    "    # caption1 키 (앞부분: 아이템 정체성)\n",
    "    caption1_keys = [\n",
    "        \"category\", \"type\", \"color.main\", \"color.sub\", \"pattern\", \"pattern_scale\", \"material.fabric\"\n",
    "    ]\n",
    "\n",
    "    caption1, caption2 = [], []\n",
    "    for p in parts:\n",
    "        key = p.split(\"=\")[0].strip()\n",
    "        if key in caption1_keys:\n",
    "            caption1.append(p)\n",
    "        else:\n",
    "            caption2.append(p)\n",
    "\n",
    "    return \" | \".join(caption1), \" | \".join(caption2)\n",
    "\n",
    "# caption1, caption2 컬럼 생성\n",
    "df[[\"caption1\", \"caption2\"]] = df[\"combined_text\"].apply(\n",
    "    lambda x: pd.Series(split_top_caption(str(x)))\n",
    ")\n",
    "\n",
    "# 저장\n",
    "df.to_csv(\"29cm/top_caption_split.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ caption1, caption2 분리 완료 → 29cm/top_caption_split.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c42d74",
   "metadata": {},
   "source": [
    "## pants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42981877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 로드\n",
    "df = pd.read_csv(\"29cm/pants_caption.csv\")\n",
    "\n",
    "def split_pants_caption(text: str):\n",
    "    \"\"\"pants category 속성들을 caption1, caption2로 분리\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\", \"\"\n",
    "\n",
    "    parts = [p.strip() for p in text.split(\"|\")]\n",
    "\n",
    "    # caption1: 전반적 외형 (핏, 기장, 재질, 색상, 패턴 등 큰 그림)\n",
    "    caption1_keys = [\n",
    "        \"category\", \"type\", \"fit\", \"rise\", \"leg.length\",\n",
    "        \"material.fabric\", \"pattern\", \"pattern_scale\",\n",
    "        \"color.main\", \"color.sub\"\n",
    "    ]\n",
    "\n",
    "    caption1, caption2 = [], []\n",
    "    for p in parts:\n",
    "        key = p.split(\"=\")[0].strip()\n",
    "        if key in caption1_keys:\n",
    "            caption1.append(p)\n",
    "        else:\n",
    "            caption2.append(p)\n",
    "\n",
    "    return \" | \".join(caption1), \" | \".join(caption2)\n",
    "\n",
    "# caption1, caption2 컬럼 생성\n",
    "df[[\"caption1\", \"caption2\"]] = df[\"combined_text\"].apply(\n",
    "    lambda x: pd.Series(split_pants_caption(str(x)))\n",
    ")\n",
    "\n",
    "# 저장\n",
    "df.to_csv(\"29cm/pants_caption_split.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ caption1, caption2 분리 완료 → 29cm/pants_caption_split.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add718f2",
   "metadata": {},
   "source": [
    "## skirt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee39457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 로드\n",
    "df = pd.read_csv(\"29cm/skirt_caption.csv\")\n",
    "\n",
    "def split_skirt_caption(text: str):\n",
    "    \"\"\"skirt category 속성들을 caption1, caption2로 분리\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\", \"\"\n",
    "\n",
    "    parts = [p.strip() for p in text.split(\"|\")]\n",
    "\n",
    "    # caption1: 전반적 외형 (카테고리, 타입, 색상, 패턴, 소재, 실루엣 등)\n",
    "    caption1_keys = [\n",
    "        \"category\", \"type\", \"skirt.length\", \"silhouette\",\n",
    "        \"material.fabric\", \"pattern\", \"pattern_scale\",\n",
    "        \"color.main\", \"color.sub\", \"color.tone\"\n",
    "    ]\n",
    "\n",
    "    caption1, caption2 = [], []\n",
    "    for p in parts:\n",
    "        key = p.split(\"=\")[0].strip()\n",
    "        if key in caption1_keys:\n",
    "            caption1.append(p)\n",
    "        else:\n",
    "            caption2.append(p)\n",
    "\n",
    "    return \" | \".join(caption1), \" | \".join(caption2)\n",
    "\n",
    "# caption1, caption2 컬럼 생성\n",
    "df[[\"caption1\", \"caption2\"]] = df[\"combined_text\"].apply(\n",
    "    lambda x: pd.Series(split_skirt_caption(str(x)))\n",
    ")\n",
    "\n",
    "# 저장\n",
    "df.to_csv(\"29cm/skirt_caption_split.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ caption1, caption2 분리 완료 → 29cm/skirt_caption_split.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c79415e",
   "metadata": {},
   "source": [
    "## dress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf00862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 로드\n",
    "df = pd.read_csv(\"29cm/dress_caption.csv\")\n",
    "\n",
    "def split_dress_caption(text: str):\n",
    "    \"\"\"dress category 속성들을 caption1, caption2로 분리\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\", \"\"\n",
    "\n",
    "    parts = [p.strip() for p in text.split(\"|\")]\n",
    "\n",
    "    # caption1: 전반적 외형 (드레스 길이, 실루엣, 소재, 색상, 패턴 등 큰 그림)\n",
    "    caption1_keys = [\n",
    "        \"category\", \"type\", \"dress.length\", \"skirt.volume\",\n",
    "        \"material.fabric\", \"pattern\", \"pattern_scale\",\n",
    "        \"color.main\", \"color.sub\"\n",
    "    ]\n",
    "\n",
    "    caption1, caption2 = [], []\n",
    "    for p in parts:\n",
    "        key = p.split(\"=\")[0].strip()\n",
    "        if key in caption1_keys:\n",
    "            caption1.append(p)\n",
    "        else:\n",
    "            caption2.append(p)\n",
    "\n",
    "    return \" | \".join(caption1), \" | \".join(caption2)\n",
    "\n",
    "# caption1, caption2 컬럼 생성\n",
    "df[[\"caption1\", \"caption2\"]] = df[\"combined_text\"].apply(\n",
    "    lambda x: pd.Series(split_dress_caption(str(x)))\n",
    ")\n",
    "\n",
    "# 저장\n",
    "df.to_csv(\"29cm/dress_caption_split.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ caption1, caption2 분리 완료 → 29cm/dress_caption_split.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a23bd61",
   "metadata": {},
   "source": [
    "# Embedding : 두 개로 나뉜 캡션을 각각 임베딩하여 평균을 내어 합치고 text 와 crop된 이미지를 Clip 모델을 통해 임베딩 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cb45c0",
   "metadata": {},
   "source": [
    "## top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d10358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Top Embedding Pipeline (caption1+caption2 평균 text 임베딩 + multi = text+image 0.5:0.5)\n",
    "# CSV 저장 시 information(원본 캡션) 컬럼만 남김\n",
    "\n",
    "import os, io, json, torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from fashion_clip.fashion_clip import FashionCLIP\n",
    "\n",
    "# ==============================\n",
    "# 0) 설정\n",
    "# ==============================\n",
    "IMAGE_DIR = \"crop_29cm\"                       # crop된 이미지 폴더\n",
    "CAPTIONS_CSV = \"29cm/top_caption_split.csv\"   # caption1, caption2 포함된 CSV\n",
    "PRODUCT_INFO_CSV = \"29cm/29cm_1000.csv\"       # [상품코드, 대분류, 소분류]\n",
    "OUTPUT_CSV = \"29cm/top_embeddings_real_final.csv\"  # 최종 산출물\n",
    "\n",
    "# 디바이스 선택\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "# 모델 로드\n",
    "fclip = FashionCLIP(\"fashion-clip\")\n",
    "try:\n",
    "    fclip.to(device)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# ==============================\n",
    "# 1) 유틸 함수\n",
    "# ==============================\n",
    "def l2_normalize(x: np.ndarray, eps: float = 1e-12) -> np.ndarray:\n",
    "    x = np.asarray(x, dtype=np.float32)\n",
    "    if x.ndim == 1:\n",
    "        x = x[None, :]\n",
    "    n = np.linalg.norm(x, axis=1, keepdims=True)\n",
    "    n = np.maximum(n, eps)\n",
    "    return (x / n).astype(np.float32)\n",
    "\n",
    "def _to_numpy_2d(x) -> np.ndarray:\n",
    "    if isinstance(x, np.ndarray):\n",
    "        arr = x\n",
    "    elif torch.is_tensor(x):\n",
    "        arr = x.detach().cpu().numpy()\n",
    "    else:\n",
    "        arr = np.asarray(x)\n",
    "    if arr.ndim == 1:\n",
    "        arr = arr[None, :]\n",
    "    return arr.astype(np.float32)\n",
    "\n",
    "def torch_empty_cache():\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "    elif device == \"mps\":\n",
    "        try:\n",
    "            torch.mps.empty_cache()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "def determine_best_batch_size(start: int = 512) -> int:\n",
    "    \"\"\"OOM 피하면서 가장 큰 batch_size 선택\"\"\"\n",
    "    if start >= 512:\n",
    "        candidates = [start,384,256,192,128,96,64,48,32,24,16,12,8,4,2,1]\n",
    "    elif start >= 256:\n",
    "        candidates = [start,192,128,96,64,48,32,24,16,12,8,4,2,1]\n",
    "    else:\n",
    "        candidates = [start,48,32,24,16,12,8,4,2,1]\n",
    "    for bs in candidates:\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                _ = fclip.encode_text([\"warmup\"] * bs, batch_size=bs)\n",
    "                dummy = Image.new(\"RGB\", (224,224), (255,255,255))\n",
    "                _ = fclip.encode_images([dummy] * bs, batch_size=bs)\n",
    "            print(f\">>> OK batch_size={bs}\")\n",
    "            return bs\n",
    "        except Exception as e:\n",
    "            print(f\"OOM/Fail at batch_size={bs} → {e}\")\n",
    "            torch_empty_cache()\n",
    "    return 1\n",
    "\n",
    "# ==============================\n",
    "# 2) 임베딩 함수\n",
    "# ==============================\n",
    "def embed_in_batches(records, batch_size: int):\n",
    "    out = []\n",
    "    n = len(records)\n",
    "    total_batches = (n + batch_size - 1) // batch_size\n",
    "\n",
    "    for bi in range(total_batches):\n",
    "        s, e = bi*batch_size, min((bi+1)*batch_size, n)\n",
    "        chunk = records[s:e]\n",
    "\n",
    "        texts1 = [r[\"caption1\"] for r in chunk]\n",
    "        texts2 = [r[\"caption2\"] for r in chunk]\n",
    "        combined_texts = [r[\"caption1\"] + \" | \" + r[\"caption2\"] for r in chunk]\n",
    "        images = [Image.open(r[\"image_path\"]).convert(\"RGB\") for r in chunk]\n",
    "\n",
    "        try:\n",
    "            with torch.no_grad(), torch.autocast(device_type='cuda', dtype=torch.float16, enabled=(device=='cuda')):\n",
    "                # caption1, caption2 임베딩\n",
    "                t1_emb = fclip.encode_text(texts1, batch_size=len(texts1))\n",
    "                t2_emb = fclip.encode_text(texts2, batch_size=len(texts2))\n",
    "                # combined_text 임베딩 (information 컬럼용)\n",
    "                t_comb_emb = fclip.encode_text(combined_texts, batch_size=len(combined_texts))\n",
    "                # 이미지 임베딩\n",
    "                v_emb = fclip.encode_images(images, batch_size=len(images))\n",
    "        finally:\n",
    "            for img in images:\n",
    "                try: img.close()\n",
    "                except: pass\n",
    "\n",
    "        t1_np = _to_numpy_2d(t1_emb)\n",
    "        t2_np = _to_numpy_2d(t2_emb)\n",
    "        t_comb_np = _to_numpy_2d(t_comb_emb)\n",
    "        v_np  = _to_numpy_2d(v_emb)\n",
    "\n",
    "        # text-only = caption1 + caption2 평균\n",
    "        text_only = l2_normalize((t1_np + t2_np) / 2)\n",
    "\n",
    "        # multi = text + image (0.5:0.5)\n",
    "        multi = l2_normalize(0.5*text_only + 0.5*l2_normalize(v_np))\n",
    "\n",
    "        # 결과 저장 (caption1, caption2 대신 information만 저장)\n",
    "        for r, info, t_vec, m_vec in zip(chunk, combined_texts, text_only, multi):\n",
    "            out.append({\n",
    "                \"id\": r[\"product_id\"],\n",
    "                \"category\": r[\"category\"],\n",
    "                \"type\": r[\"type\"],\n",
    "                \"information\": info,\n",
    "                \"text\": json.dumps(t_vec.tolist()),\n",
    "                \"multi\": json.dumps(m_vec.tolist())\n",
    "            })\n",
    "\n",
    "        torch_empty_cache()\n",
    "        print(f\"[EMBED] batch {bi+1}/{total_batches} → {e}/{n}\")\n",
    "\n",
    "    return out\n",
    "\n",
    "# ==============================\n",
    "# 3) 메인\n",
    "# ==============================\n",
    "def main():\n",
    "    if not os.path.exists(CAPTIONS_CSV):\n",
    "        raise FileNotFoundError(f\"캡션 CSV가 없습니다: {CAPTIONS_CSV}\")\n",
    "    if not os.path.exists(PRODUCT_INFO_CSV):\n",
    "        raise FileNotFoundError(f\"상품정보 CSV가 없습니다: {PRODUCT_INFO_CSV}\")\n",
    "\n",
    "    captions_df = pd.read_csv(CAPTIONS_CSV)\n",
    "    product_df = pd.read_csv(PRODUCT_INFO_CSV, dtype=str).fillna(\"\")\n",
    "    product_df = product_df.apply(lambda col: col.str.strip().str.lower())\n",
    "\n",
    "    product_map = dict(zip(product_df[\"상품코드\"], zip(product_df[\"대분류\"], product_df[\"소분류\"])))\n",
    "\n",
    "    # 한글 → 영어 매핑\n",
    "    major_map = {\"상의\": \"top\"}\n",
    "    sub_map = {\n",
    "        \"후드티\": \"hoodie\",\n",
    "        \"셔츠블라우스\": \"shirt-blouse\",\n",
    "        \"긴소매\": \"longsleeve\",\n",
    "        \"반소매\": \"shortsleeve\",\n",
    "        \"피케카라\": \"polo\",\n",
    "        \"니트스웨터\": \"knit-sweater\",\n",
    "        \"슬리브리스\": \"sleeveless\",\n",
    "    }\n",
    "\n",
    "    records = []\n",
    "    for _, row in captions_df.iterrows():\n",
    "        pid = str(row[\"product_id\"]).lower()\n",
    "        caption1 = str(row[\"caption1\"])\n",
    "        caption2 = str(row[\"caption2\"])\n",
    "\n",
    "        # category/type 매핑\n",
    "        raw_category, raw_type = product_map.get(pid, (\"unknown\",\"unknown\"))\n",
    "        category = major_map.get(raw_category, raw_category)\n",
    "        type_ = sub_map.get(raw_type, raw_type)\n",
    "\n",
    "        # 이미지 경로 탐색\n",
    "        img_path = None\n",
    "        for ext in [\".jpg\",\".jpeg\",\".png\",\".webp\",\".bmp\",\".jfif\"]:\n",
    "            candidate = os.path.join(IMAGE_DIR, f\"top_{pid}{ext}\")\n",
    "            if os.path.exists(candidate):\n",
    "                img_path = candidate\n",
    "                break\n",
    "        if not img_path:\n",
    "            continue\n",
    "\n",
    "        records.append({\n",
    "            \"product_id\": pid,\n",
    "            \"category\": category,\n",
    "            \"type\": type_,\n",
    "            \"caption1\": caption1,\n",
    "            \"caption2\": caption2,\n",
    "            \"image_path\": img_path\n",
    "        })\n",
    "\n",
    "    if not records:\n",
    "        raise RuntimeError(\"처리할 레코드가 없습니다.\")\n",
    "\n",
    "    # 배치 크기 결정\n",
    "    start_bs = 512 if device in (\"cuda\",\"mps\") else 256\n",
    "    best_bs = determine_best_batch_size(start=start_bs)\n",
    "    print(f\">>> Using batch_size={best_bs} on {device}\")\n",
    "\n",
    "    embedded = embed_in_batches(records, batch_size=best_bs)\n",
    "\n",
    "    # 저장 (최종 컬럼: id, category, type, information, text, multi)\n",
    "    df = pd.DataFrame(embedded, columns=[\"id\",\"category\",\"type\",\"information\",\"text\",\"multi\"])\n",
    "    df.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8\")\n",
    "    print(f\"✅ 임베딩 저장 완료: {OUTPUT_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311df10d",
   "metadata": {},
   "source": [
    "## pants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d126ca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Top Embedding Pipeline (caption1+caption2 평균 text 임베딩 + multi = text+image 0.5:0.5)\n",
    "# CSV 저장 시 information(원본 캡션) 컬럼만 남김\n",
    "\n",
    "import os, io, json, torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from fashion_clip.fashion_clip import FashionCLIP\n",
    "\n",
    "# ==============================\n",
    "# 0) 설정\n",
    "# ==============================\n",
    "IMAGE_DIR = \"crop_29cm\"                       # crop된 이미지 폴더\n",
    "CAPTIONS_CSV = \"29cm/pants_caption_split.csv\"   # caption1, caption2 포함된 CSV\n",
    "PRODUCT_INFO_CSV = \"29cm/29cm_1000.csv\"       # [상품코드, 대분류, 소분류]\n",
    "OUTPUT_CSV = \"29cm/pants_embeddings_real_final.csv\"  # 최종 산출물\n",
    "\n",
    "# 디바이스 선택\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "# 모델 로드\n",
    "fclip = FashionCLIP(\"fashion-clip\")\n",
    "try:\n",
    "    fclip.to(device)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# ==============================\n",
    "# 1) 유틸 함수\n",
    "# ==============================\n",
    "def l2_normalize(x: np.ndarray, eps: float = 1e-12) -> np.ndarray:\n",
    "    x = np.asarray(x, dtype=np.float32)\n",
    "    if x.ndim == 1:\n",
    "        x = x[None, :]\n",
    "    n = np.linalg.norm(x, axis=1, keepdims=True)\n",
    "    n = np.maximum(n, eps)\n",
    "    return (x / n).astype(np.float32)\n",
    "\n",
    "def _to_numpy_2d(x) -> np.ndarray:\n",
    "    if isinstance(x, np.ndarray):\n",
    "        arr = x\n",
    "    elif torch.is_tensor(x):\n",
    "        arr = x.detach().cpu().numpy()\n",
    "    else:\n",
    "        arr = np.asarray(x)\n",
    "    if arr.ndim == 1:\n",
    "        arr = arr[None, :]\n",
    "    return arr.astype(np.float32)\n",
    "\n",
    "def torch_empty_cache():\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "    elif device == \"mps\":\n",
    "        try:\n",
    "            torch.mps.empty_cache()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "def determine_best_batch_size(start: int = 512) -> int:\n",
    "    \"\"\"OOM 피하면서 가장 큰 batch_size 선택\"\"\"\n",
    "    if start >= 512:\n",
    "        candidates = [start,384,256,192,128,96,64,48,32,24,16,12,8,4,2,1]\n",
    "    elif start >= 256:\n",
    "        candidates = [start,192,128,96,64,48,32,24,16,12,8,4,2,1]\n",
    "    else:\n",
    "        candidates = [start,48,32,24,16,12,8,4,2,1]\n",
    "    for bs in candidates:\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                _ = fclip.encode_text([\"warmup\"] * bs, batch_size=bs)\n",
    "                dummy = Image.new(\"RGB\", (224,224), (255,255,255))\n",
    "                _ = fclip.encode_images([dummy] * bs, batch_size=bs)\n",
    "            print(f\">>> OK batch_size={bs}\")\n",
    "            return bs\n",
    "        except Exception as e:\n",
    "            print(f\"OOM/Fail at batch_size={bs} → {e}\")\n",
    "            torch_empty_cache()\n",
    "    return 1\n",
    "\n",
    "# ==============================\n",
    "# 2) 임베딩 함수\n",
    "# ==============================\n",
    "def embed_in_batches(records, batch_size: int):\n",
    "    out = []\n",
    "    n = len(records)\n",
    "    total_batches = (n + batch_size - 1) // batch_size\n",
    "\n",
    "    for bi in range(total_batches):\n",
    "        s, e = bi*batch_size, min((bi+1)*batch_size, n)\n",
    "        chunk = records[s:e]\n",
    "\n",
    "        texts1 = [r[\"caption1\"] for r in chunk]\n",
    "        texts2 = [r[\"caption2\"] for r in chunk]\n",
    "        combined_texts = [r[\"caption1\"] + \" | \" + r[\"caption2\"] for r in chunk]\n",
    "        images = [Image.open(r[\"image_path\"]).convert(\"RGB\") for r in chunk]\n",
    "\n",
    "        try:\n",
    "            with torch.no_grad(), torch.autocast(device_type='cuda', dtype=torch.float16, enabled=(device=='cuda')):\n",
    "                # caption1, caption2 임베딩\n",
    "                t1_emb = fclip.encode_text(texts1, batch_size=len(texts1))\n",
    "                t2_emb = fclip.encode_text(texts2, batch_size=len(texts2))\n",
    "                # combined_text 임베딩 (information 컬럼용)\n",
    "                t_comb_emb = fclip.encode_text(combined_texts, batch_size=len(combined_texts))\n",
    "                # 이미지 임베딩\n",
    "                v_emb = fclip.encode_images(images, batch_size=len(images))\n",
    "        finally:\n",
    "            for img in images:\n",
    "                try: img.close()\n",
    "                except: pass\n",
    "\n",
    "        t1_np = _to_numpy_2d(t1_emb)\n",
    "        t2_np = _to_numpy_2d(t2_emb)\n",
    "        t_comb_np = _to_numpy_2d(t_comb_emb)\n",
    "        v_np  = _to_numpy_2d(v_emb)\n",
    "\n",
    "        # text-only = caption1 + caption2 평균\n",
    "        text_only = l2_normalize((t1_np + t2_np) / 2)\n",
    "\n",
    "        # multi = text + image (0.5:0.5)\n",
    "        multi = l2_normalize(0.5*text_only + 0.5*l2_normalize(v_np))\n",
    "\n",
    "        # 결과 저장 (caption1, caption2 대신 information만 저장)\n",
    "        for r, info, t_vec, m_vec in zip(chunk, combined_texts, text_only, multi):\n",
    "            out.append({\n",
    "                \"id\": r[\"product_id\"],\n",
    "                \"category\": r[\"category\"],\n",
    "                \"type\": r[\"type\"],\n",
    "                \"information\": info,\n",
    "                \"text\": json.dumps(t_vec.tolist()),\n",
    "                \"multi\": json.dumps(m_vec.tolist())\n",
    "            })\n",
    "\n",
    "        torch_empty_cache()\n",
    "        print(f\"[EMBED] batch {bi+1}/{total_batches} → {e}/{n}\")\n",
    "\n",
    "    return out\n",
    "\n",
    "# ==============================\n",
    "# 3) 메인\n",
    "# ==============================\n",
    "def main():\n",
    "    if not os.path.exists(CAPTIONS_CSV):\n",
    "        raise FileNotFoundError(f\"캡션 CSV가 없습니다: {CAPTIONS_CSV}\")\n",
    "    if not os.path.exists(PRODUCT_INFO_CSV):\n",
    "        raise FileNotFoundError(f\"상품정보 CSV가 없습니다: {PRODUCT_INFO_CSV}\")\n",
    "\n",
    "    captions_df = pd.read_csv(CAPTIONS_CSV)\n",
    "    product_df = pd.read_csv(PRODUCT_INFO_CSV, dtype=str).fillna(\"\")\n",
    "    product_df = product_df.apply(lambda col: col.str.strip().str.lower())\n",
    "\n",
    "    product_map = dict(zip(product_df[\"상품코드\"], zip(product_df[\"대분류\"], product_df[\"소분류\"])))\n",
    "\n",
    "    # 한글 → 영어 매핑\n",
    "    major_map = {\n",
    "        \"하의\": \"pants\",\n",
    "        \"바지\": \"pants\",\n",
    "    }\n",
    "    sub_map = {\n",
    "        \"데님팬츠\": \"denim-pants\",\n",
    "        \"트레이닝조거팬츠\": \"jogger-pants\",\n",
    "        \"코튼팬츠\": \"cotton-pants\",\n",
    "        \"슈트팬츠슬랙스\": \"slacks\",  # '슈트 팬츠/슬랙스' 합쳐진 케이스\n",
    "        \"슈트슬랙스\": \"slacks\",\n",
    "        \"숏팬츠\": \"short-pants\",\n",
    "        \"카고팬츠\": \"cargo-pants\"\n",
    "    }\n",
    "\n",
    "    records = []\n",
    "    for _, row in captions_df.iterrows():\n",
    "        pid = str(row[\"product_id\"]).lower()\n",
    "        caption1 = str(row[\"caption1\"])\n",
    "        caption2 = str(row[\"caption2\"])\n",
    "\n",
    "        # category/type 매핑\n",
    "        raw_category, raw_type = product_map.get(pid, (\"unknown\",\"unknown\"))\n",
    "        category = major_map.get(raw_category, raw_category)\n",
    "        type_ = sub_map.get(raw_type, raw_type)\n",
    "\n",
    "        # 이미지 경로 탐색\n",
    "        img_path = None\n",
    "        for ext in [\".jpg\",\".jpeg\",\".png\",\".webp\",\".bmp\",\".jfif\"]:\n",
    "            candidate = os.path.join(IMAGE_DIR, f\"pants_{pid}{ext}\")\n",
    "            if os.path.exists(candidate):\n",
    "                img_path = candidate\n",
    "                break\n",
    "        if not img_path:\n",
    "            continue\n",
    "\n",
    "        records.append({\n",
    "            \"product_id\": pid,\n",
    "            \"category\": category,\n",
    "            \"type\": type_,\n",
    "            \"caption1\": caption1,\n",
    "            \"caption2\": caption2,\n",
    "            \"image_path\": img_path\n",
    "        })\n",
    "\n",
    "    if not records:\n",
    "        raise RuntimeError(\"처리할 레코드가 없습니다.\")\n",
    "\n",
    "    # 배치 크기 결정\n",
    "    start_bs = 512 if device in (\"cuda\",\"mps\") else 256\n",
    "    best_bs = determine_best_batch_size(start=start_bs)\n",
    "    print(f\">>> Using batch_size={best_bs} on {device}\")\n",
    "\n",
    "    embedded = embed_in_batches(records, batch_size=best_bs)\n",
    "\n",
    "    # 저장 (최종 컬럼: id, category, type, information, text, multi)\n",
    "    df = pd.DataFrame(embedded, columns=[\"id\",\"category\",\"type\",\"information\",\"text\",\"multi\"])\n",
    "    df.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8\")\n",
    "    print(f\"✅ 임베딩 저장 완료: {OUTPUT_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5efbb12",
   "metadata": {},
   "source": [
    "## skirt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e5de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Top Embedding Pipeline (caption1+caption2 평균 text 임베딩 + multi = text+image 0.5:0.5)\n",
    "# CSV 저장 시 information(원본 캡션) 컬럼만 남김\n",
    "\n",
    "import os, io, json, torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from fashion_clip.fashion_clip import FashionCLIP\n",
    "\n",
    "# ==============================\n",
    "# 0) 설정\n",
    "# ==============================\n",
    "IMAGE_DIR = \"crop_29cm\"                       # crop된 이미지 폴더\n",
    "CAPTIONS_CSV = \"29cm/skirt_caption_split.csv\"   # caption1, caption2 포함된 CSV\n",
    "PRODUCT_INFO_CSV = \"29cm/29cm_1000.csv\"       # [상품코드, 대분류, 소분류]\n",
    "OUTPUT_CSV = \"29cm/skirt_embeddings_real_final.csv\"  # 최종 산출물\n",
    "\n",
    "# 디바이스 선택\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "# 모델 로드\n",
    "fclip = FashionCLIP(\"fashion-clip\")\n",
    "try:\n",
    "    fclip.to(device)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# ==============================\n",
    "# 1) 유틸 함수\n",
    "# ==============================\n",
    "def l2_normalize(x: np.ndarray, eps: float = 1e-12) -> np.ndarray:\n",
    "    x = np.asarray(x, dtype=np.float32)\n",
    "    if x.ndim == 1:\n",
    "        x = x[None, :]\n",
    "    n = np.linalg.norm(x, axis=1, keepdims=True)\n",
    "    n = np.maximum(n, eps)\n",
    "    return (x / n).astype(np.float32)\n",
    "\n",
    "def _to_numpy_2d(x) -> np.ndarray:\n",
    "    if isinstance(x, np.ndarray):\n",
    "        arr = x\n",
    "    elif torch.is_tensor(x):\n",
    "        arr = x.detach().cpu().numpy()\n",
    "    else:\n",
    "        arr = np.asarray(x)\n",
    "    if arr.ndim == 1:\n",
    "        arr = arr[None, :]\n",
    "    return arr.astype(np.float32)\n",
    "\n",
    "def torch_empty_cache():\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "    elif device == \"mps\":\n",
    "        try:\n",
    "            torch.mps.empty_cache()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "def determine_best_batch_size(start: int = 512) -> int:\n",
    "    \"\"\"OOM 피하면서 가장 큰 batch_size 선택\"\"\"\n",
    "    if start >= 512:\n",
    "        candidates = [start,384,256,192,128,96,64,48,32,24,16,12,8,4,2,1]\n",
    "    elif start >= 256:\n",
    "        candidates = [start,192,128,96,64,48,32,24,16,12,8,4,2,1]\n",
    "    else:\n",
    "        candidates = [start,48,32,24,16,12,8,4,2,1]\n",
    "    for bs in candidates:\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                _ = fclip.encode_text([\"warmup\"] * bs, batch_size=bs)\n",
    "                dummy = Image.new(\"RGB\", (224,224), (255,255,255))\n",
    "                _ = fclip.encode_images([dummy] * bs, batch_size=bs)\n",
    "            print(f\">>> OK batch_size={bs}\")\n",
    "            return bs\n",
    "        except Exception as e:\n",
    "            print(f\"OOM/Fail at batch_size={bs} → {e}\")\n",
    "            torch_empty_cache()\n",
    "    return 1\n",
    "\n",
    "# ==============================\n",
    "# 2) 임베딩 함수\n",
    "# ==============================\n",
    "def embed_in_batches(records, batch_size: int):\n",
    "    out = []\n",
    "    n = len(records)\n",
    "    total_batches = (n + batch_size - 1) // batch_size\n",
    "\n",
    "    for bi in range(total_batches):\n",
    "        s, e = bi*batch_size, min((bi+1)*batch_size, n)\n",
    "        chunk = records[s:e]\n",
    "\n",
    "        texts1 = [r[\"caption1\"] for r in chunk]\n",
    "        texts2 = [r[\"caption2\"] for r in chunk]\n",
    "        combined_texts = [r[\"caption1\"] + \" | \" + r[\"caption2\"] for r in chunk]\n",
    "        images = [Image.open(r[\"image_path\"]).convert(\"RGB\") for r in chunk]\n",
    "\n",
    "        try:\n",
    "            with torch.no_grad(), torch.autocast(device_type='cuda', dtype=torch.float16, enabled=(device=='cuda')):\n",
    "                # caption1, caption2 임베딩\n",
    "                t1_emb = fclip.encode_text(texts1, batch_size=len(texts1))\n",
    "                t2_emb = fclip.encode_text(texts2, batch_size=len(texts2))\n",
    "                # combined_text 임베딩 (information 컬럼용)\n",
    "                t_comb_emb = fclip.encode_text(combined_texts, batch_size=len(combined_texts))\n",
    "                # 이미지 임베딩\n",
    "                v_emb = fclip.encode_images(images, batch_size=len(images))\n",
    "        finally:\n",
    "            for img in images:\n",
    "                try: img.close()\n",
    "                except: pass\n",
    "\n",
    "        t1_np = _to_numpy_2d(t1_emb)\n",
    "        t2_np = _to_numpy_2d(t2_emb)\n",
    "        t_comb_np = _to_numpy_2d(t_comb_emb)\n",
    "        v_np  = _to_numpy_2d(v_emb)\n",
    "\n",
    "        # text-only = caption1 + caption2 평균\n",
    "        text_only = l2_normalize((t1_np + t2_np) / 2)\n",
    "\n",
    "        # multi = text + image (0.5:0.5)\n",
    "        multi = l2_normalize(0.5*text_only + 0.5*l2_normalize(v_np))\n",
    "\n",
    "        # 결과 저장 (caption1, caption2 대신 information만 저장)\n",
    "        for r, info, t_vec, m_vec in zip(chunk, combined_texts, text_only, multi):\n",
    "            out.append({\n",
    "                \"id\": r[\"product_id\"],\n",
    "                \"category\": r[\"category\"],\n",
    "                \"type\": r[\"type\"],\n",
    "                \"information\": info,\n",
    "                \"text\": json.dumps(t_vec.tolist()),\n",
    "                \"multi\": json.dumps(m_vec.tolist())\n",
    "            })\n",
    "\n",
    "        torch_empty_cache()\n",
    "        print(f\"[EMBED] batch {bi+1}/{total_batches} → {e}/{n}\")\n",
    "\n",
    "    return out\n",
    "\n",
    "# ==============================\n",
    "# 3) 메인\n",
    "# ==============================\n",
    "def main():\n",
    "    if not os.path.exists(CAPTIONS_CSV):\n",
    "        raise FileNotFoundError(f\"캡션 CSV가 없습니다: {CAPTIONS_CSV}\")\n",
    "    if not os.path.exists(PRODUCT_INFO_CSV):\n",
    "        raise FileNotFoundError(f\"상품정보 CSV가 없습니다: {PRODUCT_INFO_CSV}\")\n",
    "\n",
    "    captions_df = pd.read_csv(CAPTIONS_CSV)\n",
    "    product_df = pd.read_csv(PRODUCT_INFO_CSV, dtype=str).fillna(\"\")\n",
    "    product_df = product_df.apply(lambda col: col.str.strip().str.lower())\n",
    "\n",
    "    product_map = dict(zip(product_df[\"상품코드\"], zip(product_df[\"대분류\"], product_df[\"소분류\"])))\n",
    "\n",
    "    # 한글 → 영어 매핑\n",
    "    major_map = {\"스커트\": \"skirt\"}\n",
    "    sub_map = {\n",
    "        \"미니스커트\": \"miniskirt\",\n",
    "        \"미디스커트\": \"midiskirt\",\n",
    "        \"롱스커트\": \"longskirt\",\n",
    "    }\n",
    "\n",
    "    records = []\n",
    "    for _, row in captions_df.iterrows():\n",
    "        pid = str(row[\"product_id\"]).lower()\n",
    "        caption1 = str(row[\"caption1\"])\n",
    "        caption2 = str(row[\"caption2\"])\n",
    "\n",
    "        # category/type 매핑\n",
    "        raw_category, raw_type = product_map.get(pid, (\"unknown\",\"unknown\"))\n",
    "        category = major_map.get(raw_category, raw_category)\n",
    "        type_ = sub_map.get(raw_type, raw_type)\n",
    "\n",
    "        # 이미지 경로 탐색\n",
    "        img_path = None\n",
    "        for ext in [\".jpg\",\".jpeg\",\".png\",\".webp\",\".bmp\",\".jfif\"]:\n",
    "            candidate = os.path.join(IMAGE_DIR, f\"skirt_{pid}{ext}\")\n",
    "            if os.path.exists(candidate):\n",
    "                img_path = candidate\n",
    "                break\n",
    "        if not img_path:\n",
    "            continue\n",
    "\n",
    "        records.append({\n",
    "            \"product_id\": pid,\n",
    "            \"category\": category,\n",
    "            \"type\": type_,\n",
    "            \"caption1\": caption1,\n",
    "            \"caption2\": caption2,\n",
    "            \"image_path\": img_path\n",
    "        })\n",
    "\n",
    "    if not records:\n",
    "        raise RuntimeError(\"처리할 레코드가 없습니다.\")\n",
    "\n",
    "    # 배치 크기 결정\n",
    "    start_bs = 512 if device in (\"cuda\",\"mps\") else 256\n",
    "    best_bs = determine_best_batch_size(start=start_bs)\n",
    "    print(f\">>> Using batch_size={best_bs} on {device}\")\n",
    "\n",
    "    embedded = embed_in_batches(records, batch_size=best_bs)\n",
    "\n",
    "    # 저장 (최종 컬럼: id, category, type, information, text, multi)\n",
    "    df = pd.DataFrame(embedded, columns=[\"id\",\"category\",\"type\",\"information\",\"text\",\"multi\"])\n",
    "    df.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8\")\n",
    "    print(f\"✅ 임베딩 저장 완료: {OUTPUT_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412ca308",
   "metadata": {},
   "source": [
    "## dress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa21803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Top Embedding Pipeline (caption1+caption2 평균 text 임베딩 + multi = text+image 0.5:0.5)\n",
    "# CSV 저장 시 information(원본 캡션) 컬럼만 남김\n",
    "\n",
    "import os, io, json, torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from fashion_clip.fashion_clip import FashionCLIP\n",
    "\n",
    "# ==============================\n",
    "# 0) 설정\n",
    "# ==============================\n",
    "IMAGE_DIR = \"crop_29cm\"                       # crop된 이미지 폴더\n",
    "CAPTIONS_CSV = \"29cm/dress_caption_split.csv\"   # caption1, caption2 포함된 CSV\n",
    "PRODUCT_INFO_CSV = \"29cm/29cm_1000.csv\"       # [상품코드, 대분류, 소분류]\n",
    "OUTPUT_CSV = \"29cm/dress_embeddings_real_final.csv\"  # 최종 산출물\n",
    "\n",
    "# 디바이스 선택\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "# 모델 로드\n",
    "fclip = FashionCLIP(\"fashion-clip\")\n",
    "try:\n",
    "    fclip.to(device)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# ==============================\n",
    "# 1) 유틸 함수\n",
    "# ==============================\n",
    "def l2_normalize(x: np.ndarray, eps: float = 1e-12) -> np.ndarray:\n",
    "    x = np.asarray(x, dtype=np.float32)\n",
    "    if x.ndim == 1:\n",
    "        x = x[None, :]\n",
    "    n = np.linalg.norm(x, axis=1, keepdims=True)\n",
    "    n = np.maximum(n, eps)\n",
    "    return (x / n).astype(np.float32)\n",
    "\n",
    "def _to_numpy_2d(x) -> np.ndarray:\n",
    "    if isinstance(x, np.ndarray):\n",
    "        arr = x\n",
    "    elif torch.is_tensor(x):\n",
    "        arr = x.detach().cpu().numpy()\n",
    "    else:\n",
    "        arr = np.asarray(x)\n",
    "    if arr.ndim == 1:\n",
    "        arr = arr[None, :]\n",
    "    return arr.astype(np.float32)\n",
    "\n",
    "def torch_empty_cache():\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "    elif device == \"mps\":\n",
    "        try:\n",
    "            torch.mps.empty_cache()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "def determine_best_batch_size(start: int = 512) -> int:\n",
    "    \"\"\"OOM 피하면서 가장 큰 batch_size 선택\"\"\"\n",
    "    if start >= 512:\n",
    "        candidates = [start,384,256,192,128,96,64,48,32,24,16,12,8,4,2,1]\n",
    "    elif start >= 256:\n",
    "        candidates = [start,192,128,96,64,48,32,24,16,12,8,4,2,1]\n",
    "    else:\n",
    "        candidates = [start,48,32,24,16,12,8,4,2,1]\n",
    "    for bs in candidates:\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                _ = fclip.encode_text([\"warmup\"] * bs, batch_size=bs)\n",
    "                dummy = Image.new(\"RGB\", (224,224), (255,255,255))\n",
    "                _ = fclip.encode_images([dummy] * bs, batch_size=bs)\n",
    "            print(f\">>> OK batch_size={bs}\")\n",
    "            return bs\n",
    "        except Exception as e:\n",
    "            print(f\"OOM/Fail at batch_size={bs} → {e}\")\n",
    "            torch_empty_cache()\n",
    "    return 1\n",
    "\n",
    "# ==============================\n",
    "# 2) 임베딩 함수\n",
    "# ==============================\n",
    "def embed_in_batches(records, batch_size: int):\n",
    "    out = []\n",
    "    n = len(records)\n",
    "    total_batches = (n + batch_size - 1) // batch_size\n",
    "\n",
    "    for bi in range(total_batches):\n",
    "        s, e = bi*batch_size, min((bi+1)*batch_size, n)\n",
    "        chunk = records[s:e]\n",
    "\n",
    "        texts1 = [r[\"caption1\"] for r in chunk]\n",
    "        texts2 = [r[\"caption2\"] for r in chunk]\n",
    "        combined_texts = [r[\"caption1\"] + \" | \" + r[\"caption2\"] for r in chunk]\n",
    "        images = [Image.open(r[\"image_path\"]).convert(\"RGB\") for r in chunk]\n",
    "\n",
    "        try:\n",
    "            with torch.no_grad(), torch.autocast(device_type='cuda', dtype=torch.float16, enabled=(device=='cuda')):\n",
    "                # caption1, caption2 임베딩\n",
    "                t1_emb = fclip.encode_text(texts1, batch_size=len(texts1))\n",
    "                t2_emb = fclip.encode_text(texts2, batch_size=len(texts2))\n",
    "                # combined_text 임베딩 (information 컬럼용)\n",
    "                t_comb_emb = fclip.encode_text(combined_texts, batch_size=len(combined_texts))\n",
    "                # 이미지 임베딩\n",
    "                v_emb = fclip.encode_images(images, batch_size=len(images))\n",
    "        finally:\n",
    "            for img in images:\n",
    "                try: img.close()\n",
    "                except: pass\n",
    "\n",
    "        t1_np = _to_numpy_2d(t1_emb)\n",
    "        t2_np = _to_numpy_2d(t2_emb)\n",
    "        t_comb_np = _to_numpy_2d(t_comb_emb)\n",
    "        v_np  = _to_numpy_2d(v_emb)\n",
    "\n",
    "        # text-only = caption1 + caption2 평균\n",
    "        text_only = l2_normalize((t1_np + t2_np) / 2)\n",
    "\n",
    "        # multi = text + image (0.5:0.5)\n",
    "        multi = l2_normalize(0.5*text_only + 0.5*l2_normalize(v_np))\n",
    "\n",
    "        # 결과 저장 (caption1, caption2 대신 information만 저장)\n",
    "        for r, info, t_vec, m_vec in zip(chunk, combined_texts, text_only, multi):\n",
    "            out.append({\n",
    "                \"id\": r[\"product_id\"],\n",
    "                \"category\": r[\"category\"],\n",
    "                \"type\": r[\"type\"],\n",
    "                \"information\": info,\n",
    "                \"text\": json.dumps(t_vec.tolist()),\n",
    "                \"multi\": json.dumps(m_vec.tolist())\n",
    "            })\n",
    "\n",
    "        torch_empty_cache()\n",
    "        print(f\"[EMBED] batch {bi+1}/{total_batches} → {e}/{n}\")\n",
    "\n",
    "    return out\n",
    "\n",
    "# ==============================\n",
    "# 3) 메인\n",
    "# ==============================\n",
    "def main():\n",
    "    if not os.path.exists(CAPTIONS_CSV):\n",
    "        raise FileNotFoundError(f\"캡션 CSV가 없습니다: {CAPTIONS_CSV}\")\n",
    "    if not os.path.exists(PRODUCT_INFO_CSV):\n",
    "        raise FileNotFoundError(f\"상품정보 CSV가 없습니다: {PRODUCT_INFO_CSV}\")\n",
    "\n",
    "    captions_df = pd.read_csv(CAPTIONS_CSV)\n",
    "    product_df = pd.read_csv(PRODUCT_INFO_CSV, dtype=str).fillna(\"\")\n",
    "    product_df = product_df.apply(lambda col: col.str.strip().str.lower())\n",
    "\n",
    "    product_map = dict(zip(product_df[\"상품코드\"], zip(product_df[\"대분류\"], product_df[\"소분류\"])))\n",
    "\n",
    "    # 한글 → 영어 매핑\n",
    "    major_map = {\"원피스\":\"dress\"}\n",
    "    sub_map = {\n",
    "        \"미니원피스\":\"minidress\",\n",
    "        \"미디원피스\":\"mididress\",\n",
    "        \"맥시원피스\":\"maxidress\",\n",
    "    }\n",
    "\n",
    "    records = []\n",
    "    for _, row in captions_df.iterrows():\n",
    "        pid = str(row[\"product_id\"]).lower()\n",
    "        caption1 = str(row[\"caption1\"])\n",
    "        caption2 = str(row[\"caption2\"])\n",
    "\n",
    "        # category/type 매핑\n",
    "        raw_category, raw_type = product_map.get(pid, (\"unknown\",\"unknown\"))\n",
    "        category = major_map.get(raw_category, raw_category)\n",
    "        type_ = sub_map.get(raw_type, raw_type)\n",
    "\n",
    "        # 이미지 경로 탐색\n",
    "        img_path = None\n",
    "        for ext in [\".jpg\",\".jpeg\",\".png\",\".webp\",\".bmp\",\".jfif\"]:\n",
    "            candidate = os.path.join(IMAGE_DIR, f\"dress_{pid}{ext}\")\n",
    "            if os.path.exists(candidate):\n",
    "                img_path = candidate\n",
    "                break\n",
    "        if not img_path:\n",
    "            continue\n",
    "\n",
    "        records.append({\n",
    "            \"product_id\": pid,\n",
    "            \"category\": category,\n",
    "            \"type\": type_,\n",
    "            \"caption1\": caption1,\n",
    "            \"caption2\": caption2,\n",
    "            \"image_path\": img_path\n",
    "        })\n",
    "\n",
    "    if not records:\n",
    "        raise RuntimeError(\"처리할 레코드가 없습니다.\")\n",
    "\n",
    "    # 배치 크기 결정\n",
    "    start_bs = 512 if device in (\"cuda\",\"mps\") else 256\n",
    "    best_bs = determine_best_batch_size(start=start_bs)\n",
    "    print(f\">>> Using batch_size={best_bs} on {device}\")\n",
    "\n",
    "    embedded = embed_in_batches(records, batch_size=best_bs)\n",
    "\n",
    "    # 저장 (최종 컬럼: id, category, type, information, text, multi)\n",
    "    df = pd.DataFrame(embedded, columns=[\"id\",\"category\",\"type\",\"information\",\"text\",\"multi\"])\n",
    "    df.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8\")\n",
    "    print(f\"✅ 임베딩 저장 완료: {OUTPUT_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93d1b99",
   "metadata": {},
   "source": [
    "# Qdrant upload : Qdrant 에 데이터 삽입"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549c00e8",
   "metadata": {},
   "source": [
    "## top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b13c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "from qdrant_client import QdrantClient, models\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 0. .env 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 1. 데이터 불러오기\n",
    "df = pd.read_csv(\"29cm/top_embeddings_real_final.csv\")\n",
    "\n",
    "# 2. 환경변수에서 QDRANT_API_KEY 불러오기\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
    "\n",
    "# 3. 클라이언트 연결\n",
    "client = QdrantClient(\n",
    "    url=\"http://43.201.185.192:6333\",\n",
    "    api_key=QDRANT_API_KEY,\n",
    "    prefer_grpc=False,\n",
    "    timeout=120.0\n",
    ")\n",
    "\n",
    "# 4. 컬렉션 이름\n",
    "COLLECTION_NAME = \"ivlle\"\n",
    "\n",
    "# 5. 배치 업서트\n",
    "BATCH = 500\n",
    "total = len(df)\n",
    "\n",
    "for i in range(0, total, BATCH):\n",
    "    sl = df.iloc[i:i+BATCH]\n",
    "    points = []\n",
    "    for _, row in sl.iterrows():\n",
    "        payload = {\n",
    "            \"category\": row[\"category\"],\n",
    "            \"type\": row[\"type\"],\n",
    "            \"information\": row[\"information\"],\n",
    "        }\n",
    "        vec_text = ast.literal_eval(row[\"text\"])   # 문자열 → 리스트 변환\n",
    "        vec_multi = ast.literal_eval(row[\"multi\"])\n",
    "        \n",
    "        points.append(\n",
    "            models.PointStruct(\n",
    "                id=int(row[\"id\"]),\n",
    "                vector={\n",
    "                    \"text\": vec_text,\n",
    "                    \"multi\": vec_multi,\n",
    "                },\n",
    "                payload=payload\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    client.upsert(collection_name=COLLECTION_NAME, points=points)\n",
    "    print(f\"✅ Uploaded {i+len(sl)}/{total}\")\n",
    "\n",
    "print(\"🎉 모든 데이터 업서트 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747522f8",
   "metadata": {},
   "source": [
    "## pants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d519b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "from qdrant_client import QdrantClient, models\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 0. .env 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 1. 데이터 불러오기\n",
    "df = pd.read_csv(\"29cm/pants_embeddings_real_final.csv\")\n",
    "\n",
    "# 2. 환경변수에서 QDRANT_API_KEY 불러오기\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
    "\n",
    "# 3. 클라이언트 연결\n",
    "client = QdrantClient(\n",
    "    url=\"http://43.201.185.192:6333\",\n",
    "    api_key=QDRANT_API_KEY,\n",
    "    prefer_grpc=False,\n",
    "    timeout=120.0\n",
    ")\n",
    "\n",
    "# 4. 컬렉션 이름\n",
    "COLLECTION_NAME = \"ivlle\"\n",
    "\n",
    "# 5. 배치 업서트\n",
    "BATCH = 500\n",
    "total = len(df)\n",
    "\n",
    "for i in range(0, total, BATCH):\n",
    "    sl = df.iloc[i:i+BATCH]\n",
    "    points = []\n",
    "    for _, row in sl.iterrows():\n",
    "        payload = {\n",
    "            \"category\": row[\"category\"],\n",
    "            \"type\": row[\"type\"],\n",
    "            \"information\": row[\"information\"],\n",
    "        }\n",
    "        vec_text = ast.literal_eval(row[\"text\"])   # 문자열 → 리스트 변환\n",
    "        vec_multi = ast.literal_eval(row[\"multi\"])\n",
    "        \n",
    "        points.append(\n",
    "            models.PointStruct(\n",
    "                id=int(row[\"id\"]),\n",
    "                vector={\n",
    "                    \"text\": vec_text,\n",
    "                    \"multi\": vec_multi,\n",
    "                },\n",
    "                payload=payload\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    client.upsert(collection_name=COLLECTION_NAME, points=points)\n",
    "    print(f\"✅ Uploaded {i+len(sl)}/{total}\")\n",
    "\n",
    "print(\"🎉 모든 데이터 업서트 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a204da6",
   "metadata": {},
   "source": [
    "## skirt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68d15b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "from qdrant_client import QdrantClient, models\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 0. .env 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 1. 데이터 불러오기\n",
    "df = pd.read_csv(\"29cm/skirt_embeddings_real_final.csv\")\n",
    "\n",
    "# 2. 환경변수에서 QDRANT_API_KEY 불러오기\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
    "\n",
    "# 3. 클라이언트 연결\n",
    "client = QdrantClient(\n",
    "    url=\"http://43.201.185.192:6333\",\n",
    "    api_key=QDRANT_API_KEY,\n",
    "    prefer_grpc=False,\n",
    "    timeout=120.0\n",
    ")\n",
    "\n",
    "# 4. 컬렉션 이름\n",
    "COLLECTION_NAME = \"ivlle\"\n",
    "\n",
    "# 5. 배치 업서트\n",
    "BATCH = 500\n",
    "total = len(df)\n",
    "\n",
    "for i in range(0, total, BATCH):\n",
    "    sl = df.iloc[i:i+BATCH]\n",
    "    points = []\n",
    "    for _, row in sl.iterrows():\n",
    "        payload = {\n",
    "            \"category\": row[\"category\"],\n",
    "            \"type\": row[\"type\"],\n",
    "            \"information\": row[\"information\"],\n",
    "        }\n",
    "        vec_text = ast.literal_eval(row[\"text\"])   # 문자열 → 리스트 변환\n",
    "        vec_multi = ast.literal_eval(row[\"multi\"])\n",
    "        \n",
    "        points.append(\n",
    "            models.PointStruct(\n",
    "                id=int(row[\"id\"]),\n",
    "                vector={\n",
    "                    \"text\": vec_text,\n",
    "                    \"multi\": vec_multi,\n",
    "                },\n",
    "                payload=payload\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    client.upsert(collection_name=COLLECTION_NAME, points=points)\n",
    "    print(f\"✅ Uploaded {i+len(sl)}/{total}\")\n",
    "\n",
    "print(\"🎉 모든 데이터 업서트 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05cb398",
   "metadata": {},
   "source": [
    "## dress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbd4b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "from qdrant_client import QdrantClient, models\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 0. .env 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 1. 데이터 불러오기\n",
    "df = pd.read_csv(\"29cm/dress_embeddings_real_final.csv\")\n",
    "\n",
    "# 2. 환경변수에서 QDRANT_API_KEY 불러오기\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
    "\n",
    "# 3. 클라이언트 연결\n",
    "client = QdrantClient(\n",
    "    url=\"http://43.201.185.192:6333\",\n",
    "    api_key=QDRANT_API_KEY,\n",
    "    prefer_grpc=False,\n",
    "    timeout=120.0\n",
    ")\n",
    "\n",
    "# 4. 컬렉션 이름\n",
    "COLLECTION_NAME = \"ivlle\"\n",
    "\n",
    "# 5. 배치 업서트\n",
    "BATCH = 500\n",
    "total = len(df)\n",
    "\n",
    "for i in range(0, total, BATCH):\n",
    "    sl = df.iloc[i:i+BATCH]\n",
    "    points = []\n",
    "    for _, row in sl.iterrows():\n",
    "        payload = {\n",
    "            \"category\": row[\"category\"],\n",
    "            \"type\": row[\"type\"],\n",
    "            \"information\": row[\"information\"],\n",
    "        }\n",
    "        vec_text = ast.literal_eval(row[\"text\"])   # 문자열 → 리스트 변환\n",
    "        vec_multi = ast.literal_eval(row[\"multi\"])\n",
    "        \n",
    "        points.append(\n",
    "            models.PointStruct(\n",
    "                id=int(row[\"id\"]),\n",
    "                vector={\n",
    "                    \"text\": vec_text,\n",
    "                    \"multi\": vec_multi,\n",
    "                },\n",
    "                payload=payload\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    client.upsert(collection_name=COLLECTION_NAME, points=points)\n",
    "    print(f\"✅ Uploaded {i+len(sl)}/{total}\")\n",
    "\n",
    "print(\"🎉 모든 데이터 업서트 완료\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
