import os
import json
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from openai import OpenAI
from dotenv import load_dotenv
import asyncio

# Agent imports
from services.agents.search_agent import SearchAgent, SearchAgentResult
from services.agents.conversation_agent import ConversationAgent, ConversationAgentResult
from services.agents.weather_agent import WeatherAgent, WeatherAgentResult
from services.agents.general_agent import GeneralAgent, GeneralAgentResult
from services.agents.unified_summary_agent import UnifiedSummaryAgent, UnifiedSummaryResult
from services.agents.followup_agent import FollowUpAgent, FollowUpAgentResult

# Legacy imports for compatibility
# Legacy IntentAnalyzer ì œê±°ë¨ - í˜„ì¬ MainAnalyzerë§Œ ì‚¬ìš©
from services.clothing_recommender import recommend_clothing_by_weather
# Legacy imports ì™„ì „ ì œê±°ë¨ - ëª¨ë“  ê¸°ëŠ¥ì´ ì—ì´ì „íŠ¸ë¡œ í†µí•©ë¨
from crud.chat_crud import (get_recent_qa_summaries, get_qa_pair_for_summary, 
                           update_message_summary, get_chat_history_for_llm)
from utils.safe_utils import safe_lower

load_dotenv()

# IntentResult í´ë˜ìŠ¤ ì •ì˜ (ê¸°ì¡´ intent_analyzerì—ì„œ ì´ë™)
@dataclass
class IntentResult:
    intent: str  # 'search', 'conversation', 'followup', 'weather', 'general'
    confidence: float
    extracted_info: Dict
    original_query: str

@dataclass
class LangGraphState:
    """LangGraph ìƒíƒœ ê´€ë¦¬"""
    user_input: str
    session_id: str  # UUIDë¥¼ ë¬¸ìì—´ë¡œ ì²˜ë¦¬
    user_id: int
    intent: str = ""
    extracted_info: Dict = None
    context_summaries: List[str] = None
    agent_result: Any = None
    final_message: str = ""
    products: List[Dict] = None
    latitude: Optional[float] = None
    longitude: Optional[float] = None
    
    def __post_init__(self):
        if self.extracted_info is None:
            self.extracted_info = {}
        if self.context_summaries is None:
            self.context_summaries = []
        if self.products is None:
            self.products = []

@dataclass
class LLMResponse:
    """LLM ì‘ë‹µ êµ¬ì¡°"""
    final_message: str
    products: List[Dict]
    analysis_result: Any  # IntentResult ë˜ëŠ” MainAnalysisResult
    summary_result: Optional[UnifiedSummaryResult] = None
    metadata: Dict = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}



class MainAnalyzer:
    """ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ë©”ì¸ ë¶„ì„ê¸° (ì»¨í…ìŠ¤íŠ¸ í¬í•¨ ì˜ë„ ë¶„ì„ìš©)"""
    
    def __init__(self):
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.model = "gpt-4o-mini"
    
    def analyze_with_prompt(self, user_input: str, context: str = "", session_summary: str = "") -> Dict:
        """í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì¢…í•©ì ì¸ ë¶„ì„ ìˆ˜í–‰"""
        
        system_prompt = """ë‹¹ì‹ ì€ ì˜ë¥˜ ì¶”ì²œ ì‹œìŠ¤í…œì˜ ë©”ì¸ ë¶„ì„ê¸°ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì…ë ¥ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:

1. Intent ë¶„ë¥˜: search, conversation, weather, general
2. í•„í„°ë§ ì¡°ê±´ ì¶”ì¶œ
3. ë¶„ì„ ìš”ì•½ ìƒì„±

ì»¨í…ìŠ¤íŠ¸ ì •ë³´:
- ì´ì „ ëŒ€í™” ë‚´ìš©: {context}
- ì„¸ì…˜ ìš”ì•½: {session_summary}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
    "intent": "search|conversation|followup|weather|general",
    "confidence": 0.0-1.0,
    "filtering_conditions": {{
        "colors": ["ì¶”ì¶œëœ ìƒ‰ìƒë“¤"],
        "categories": ["ì¶”ì¶œëœ ì¹´í…Œê³ ë¦¬ë“¤"],
        "situations": ["ì¶”ì¶œëœ ìƒí™©ë“¤"],
        "styles": ["ì¶”ì¶œëœ ìŠ¤íƒ€ì¼ë“¤"],
        "brands": ["ì¶”ì¶œëœ ë¸Œëœë“œë“¤"],
        "locations": ["ì§€ì—­ëª…ë“¤"]
    }},
    "analysis_summary": "ë¶„ì„ ê²°ê³¼ ìš”ì•½"
}}

Intent ë¶„ë¥˜ ê¸°ì¤€:
- search: êµ¬ì²´ì ì¸ ìƒí’ˆ ê²€ìƒ‰ ("íŒŒë€ìƒ‰ ì…”ì¸ ", "ì²­ë°”ì§€ ì¶”ì²œ", "ë‚˜ì´í‚¤ ìš´ë™í™”")
- conversation: ìƒí™©ë³„ ì¶”ì²œ ("ë°ì´íŠ¸ë£©", "ë©´ì ‘ë³µ", "íŒŒí‹°ë£©")  
- followup: ì´ì „ ì¶”ì²œì— ëŒ€í•œ í›„ì† ì§ˆë¬¸ ("ì´ê²ƒë“¤ì¤‘ì— ì œì¼ ì‹¼ê±°", "ë” ë¹„ì‹¼ ê²ƒë„ ìˆì–´?", "ì²« ë²ˆì§¸ê°€ ì¢‹ì„ê¹Œ?")
- weather: ë‚ ì”¨ ê´€ë ¨ ("ì˜¤ëŠ˜ ë‚ ì”¨", "ì„œìš¸ ë‚ ì”¨")
- general: ì¼ë°˜ ëŒ€í™” ("ì•ˆë…•", "ê³ ë§ˆì›Œ")

í•„í„°ë§ ì¡°ê±´ ì¶”ì¶œ ê¸°ì¤€:
- colors: ìƒ‰ìƒ ê´€ë ¨ ("ë¹¨ê°„ìƒ‰", "íŒŒë€ìƒ‰", "ê²€ì€ìƒ‰", "í°ìƒ‰", "ë² ì´ì§€", "ë„¤ì´ë¹„", "ì¹´í‚¤", "ë¯¼íŠ¸", "ì™€ì¸", "ì˜¬ë¦¬ë¸Œ" ë“±)
- categories: ëŒ€ë¶„ë¥˜/ì†Œë¶„ë¥˜ ("ìƒì˜", "ë°”ì§€", "ìŠ¤ì»¤íŠ¸", "ì›í”¼ìŠ¤", "ê¸´ì†Œë§¤", "ë°˜ì†Œë§¤", "í›„ë“œí‹°", "ë‹ˆíŠ¸/ìŠ¤ì›¨í„°", "ì…”ì¸ /ë¸”ë¼ìš°ìŠ¤", "í”¼ì¼€/ì¹´ë¼", "ìŠ¬ë¦¬ë¸Œë¦¬ìŠ¤", "ë°ë‹˜íŒ¬ì¸ ", "ì½”íŠ¼íŒ¬ì¸ ", "ìŠˆíŠ¸íŒ¬ì¸ /ìŠ¬ë™ìŠ¤", "ì¹´ê³ íŒ¬ì¸ ", "íŠ¸ë ˆì´ë‹/ì¡°ê±°íŒ¬ì¸ ", "ìˆíŒ¬ì¸ ", "ë¡±ìŠ¤ì»¤íŠ¸", "ë¯¸ë‹ˆìŠ¤ì»¤íŠ¸", "ë¯¸ë””ìŠ¤ì»¤íŠ¸", "ë§¥ì‹œì›í”¼ìŠ¤", "ë¯¸ë‹ˆì›í”¼ìŠ¤", "ë¯¸ë””ì›í”¼ìŠ¤")
- brands: ë¸Œëœë“œëª… ("ë‚˜ì´í‚¤", "ì•„ë””ë‹¤ìŠ¤", "ìœ ë‹ˆí´ë¡œ", "ZARA", "H&M" ë“±)
- situations: ìƒí™©/ì¥ì†Œ ("ë°ì´íŠ¸", "ë©´ì ‘", "íŒŒí‹°", "ìš´ë™", "ì—¬í–‰", "ì¶œê·¼", "ìºì£¼ì–¼" ë“±)
- styles: ìŠ¤íƒ€ì¼ ("ìºì£¼ì–¼", "ì •ì¥", "ìŠ¤í¬í‹°", "ë¹ˆí‹°ì§€", "ë¯¸ë‹ˆë©€" ë“±)

**ì¤‘ìš”**: 
1. ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì´ì „ì— ìƒí’ˆ ì¶”ì²œê³¼ ì—°ê´€ì´ ìˆëŠ” ì§ˆë¬¸ì´ë¼ë©´, ê·¸ ìƒí’ˆë“¤ì— ëŒ€í•œ ì§ˆë¬¸ì€ ë°˜ë“œì‹œ 'followup'ìœ¼ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.
"""
        messages = [
            {"role": "system", "content": system_prompt.format(
                context=context,
                session_summary=session_summary
            )},
            {"role": "user", "content": f"ì‚¬ìš©ì ì…ë ¥: {user_input}"}
        ]
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.2,
                max_tokens=800
            )
            
            result = json.loads(response.choices[0].message.content)
            return result
            
        except Exception as e:
            print(f"ë©”ì¸ ë¶„ì„ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "intent": "general",
                "confidence": 0.0,
                "filtering_conditions": {},
                "analysis_summary": "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"
            }



class LLMService:
    """LangGraph ê¸°ë°˜ LLM ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        # Core analyzers (ë©”ëª¨ë¦¬ ë¶„ì„ê¸° ì œê±°, ë©”ì¸ ë¶„ì„ê¸°ë§Œ ì‚¬ìš©)
        self.main_analyzer = MainAnalyzer()
        
        # Specialized agents
        self.search_agent = SearchAgent()
        self.conversation_agent = ConversationAgent()
        self.weather_agent = WeatherAgent()
        self.general_agent = GeneralAgent()
        self.unified_summary_agent = UnifiedSummaryAgent()
        self.followup_agent = FollowUpAgent()
        print("âœ… FollowUpAgent ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ê¸°ì¡´ IntentAnalyzer ì œê±° - í•­ìƒ MainAnalyzer ì‚¬ìš©
    
    async def process_user_input(self, user_input: str, session_id: str, user_id: int, 
                                available_products: List[Dict], db=None, 
                                latitude: Optional[float] = None, 
                                longitude: Optional[float] = None) -> LLMResponse:
        """LangGraph ìŠ¤íƒ€ì¼ë¡œ ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬"""
        

        
        # ì´ˆê¸° ìƒíƒœ ìƒì„±
        state = LangGraphState(
            user_input=user_input,
            session_id=session_id,
            user_id=user_id,
            latitude=latitude,
            longitude=longitude
        )
        
        # LangGraph ìŠ¤íƒ€ì¼ ì²˜ë¦¬ í”Œë¡œìš°
        state = await self._memory_analysis_node(state, db)
        state = await self._intent_analysis_node(state, db)
        state = await self._agent_execution_node(state, available_products, db)
        state = await self._summary_update_node(state, db)
        
        # ë¶„ì„ ê²°ê³¼ êµ¬ì„± (í•­ìƒ IntentResultë¡œ í†µì¼)
        
        # í•­ìƒ IntentResultë¡œ í†µì¼
        analysis_result = IntentResult(
            intent=state.intent,
            confidence=1.0,
            extracted_info=state.extracted_info if hasattr(state, 'extracted_info') else {},
            original_query=state.user_input
        )

        # ìµœì¢… ì‘ë‹µ êµ¬ì„±
        return LLMResponse(
            final_message=state.final_message,
            products=state.products,
            analysis_result=analysis_result,
            summary_result=state.summary_result if hasattr(state, 'summary_result') else None,
            metadata={
                "intent": state.intent,
                "always_uses_context": True,
                "agent_type": getattr(analysis_result, 'metadata', {}).get('agent_type', state.intent),
                "context_summaries_count": len(state.context_summaries)
            }
        )
    
    async def _memory_analysis_node(self, state: LangGraphState, db) -> LangGraphState:
        """ë©”ëª¨ë¦¬ ë¡œë“œ ë…¸ë“œ - í•­ìƒ ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ"""
        if db:
            state.context_summaries = get_recent_qa_summaries(db, state.session_id, limit=3)
        else:
            state.context_summaries = []
        
        return state
    
    async def _intent_analysis_node(self, state: LangGraphState, db) -> LangGraphState:
        """ì˜ë„ ë¶„ì„ ë…¸ë“œ - í•­ìƒ ë©”ëª¨ë¦¬ ê¸°ë°˜ ë¶„ì„ ì‚¬ìš©"""
        context_str = " | ".join(state.context_summaries) if state.context_summaries else "ì´ì „ ëŒ€í™” ì—†ìŒ"
        
        analysis_result = self.main_analyzer.analyze_with_prompt(
            state.user_input, context_str, ""
        )
        
        state.intent = analysis_result.get("intent", "general")
        state.extracted_info = analysis_result.get("filtering_conditions", {})
        
        return state
    
    async def _agent_execution_node(self, state: LangGraphState, available_products: List[Dict], db) -> LangGraphState:
        """Agent ì‹¤í–‰ ë…¸ë“œ - ì˜ë„ì— ë”°ë¼ ì ì ˆí•œ Agent í˜¸ì¶œ"""
        try:
            if state.intent == "followup":
                result = self.followup_agent.process_follow_up_question(
                    state.user_input, 
                    db, 
                    state.user_id,
                    state.session_id
                )
                
                state.agent_result = result
                state.final_message = result.message
                state.products = result.products
                
            elif state.intent == "search":
                # Search Agent ì‹¤í–‰
                result = self.search_agent.process_search_request(
                    state.user_input, 
                    state.extracted_info, 
                    available_products,
                    context_info={"previous_summaries": state.context_summaries} if state.context_summaries else None,
                    db=db,
                    user_id=state.user_id
                )
                state.agent_result = result
                state.final_message = result.message
                state.products = result.products
                
            elif state.intent == "conversation":
                # Conversation Agent ì‹¤í–‰ (ìˆœìˆ˜ ìƒí™©ë³„ ì¶”ì²œë§Œ)
                result = self.conversation_agent.process_conversation_request(
                    state.user_input,
                    state.extracted_info,
                    available_products,
                    context_summaries=state.context_summaries,
                    db=db,
                    user_id=state.user_id
                )
                state.agent_result = result
                state.final_message = result.message
                state.products = result.products
                
            elif state.intent == "weather":
                # Weather Agent ì‹¤í–‰
                result = await self.weather_agent.process_weather_request(
                    state.user_input,
                    state.extracted_info,
                    latitude=state.latitude,
                    longitude=state.longitude
                )
                state.agent_result = result
                state.final_message = result.message
                state.products = result.products
                
                # ë‚ ì”¨ ì‘ë‹µì— ì˜ë¥˜ ì¶”ì²œ ì¶”ê°€
                if result.success:
                    state = await self._enhance_weather_with_clothing(state, db)
                
            else:  # general
                # General Agent ì‹¤í–‰
                result = self.general_agent.process_general_request(
                    state.user_input,
                    state.extracted_info,
                    context_summaries=state.context_summaries
                )
                state.agent_result = result
                state.final_message = result.message
                state.products = result.products
                
        except Exception as e:
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¼ë°˜ ì—ì´ì „íŠ¸ë¡œ fallback
            try:
                result = self.general_agent.process_general_request(
                    state.user_input,
                    state.extracted_info if hasattr(state, 'extracted_info') else {},
                    context_summaries=state.context_summaries
                )
                state.agent_result = result
                state.final_message = result.message
                state.products = result.products
            except Exception:
                state.final_message = "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                state.products = []
        
        return state
    
    async def _summary_update_node(self, state: LangGraphState, db) -> LangGraphState:
        """í†µí•© ìš”ì•½ ì—…ë°ì´íŠ¸ ë…¸ë“œ - LLM ìµœì¢… ë‹µë³€ê¹Œì§€ í¬í•¨í•œ ì™„ì „í•œ ìš”ì•½"""
        if not db:
            return state
        
        try:
            # ê¸°ì¡´ ìš”ì•½ ì¡°íšŒ
            existing_summary = None
            try:
                from crud.chat_crud import get_recent_qa_summaries
                recent_summaries = get_recent_qa_summaries(db, state.session_id, limit=1)
                if recent_summaries:
                    existing_summary = recent_summaries[0]
            except Exception:
                pass
            
            # í†µí•© ì„œë¨¸ë¦¬ ì—ì´ì „íŠ¸ë¡œ ì™„ì „í•œ Q/A ìš”ì•½ ìƒì„±
            summary_result = self.unified_summary_agent.process_complete_qa_summary(
                user_input=state.user_input,
                llm_final_response=state.final_message,
                existing_summary=existing_summary
            )
            
            # ìƒíƒœì— ìš”ì•½ ì •ë³´ ì €ì¥
            state.summary_to_save = summary_result.summary_text
            state.summary_result = summary_result
            
        except Exception:
            # ì˜¤ë¥˜ ì‹œ ê°„ë‹¨í•œ fallback ìš”ì•½ ìƒì„±
            fallback_summary = f"Q: {state.user_input[:30]}... â†’ A: {state.final_message[:50]}..."
            state.summary_to_save = fallback_summary
        
        return state
    
    async def _enhance_weather_with_clothing(self, state: LangGraphState, db) -> LangGraphState:
        """ë‚ ì”¨ ì‘ë‹µì— ì‹¤ì œ ìƒí’ˆ ì¶”ì²œ ì¶”ê°€ (CommonSearch ì‚¬ìš©)"""
        try:
            # ë‚ ì”¨ ì •ë³´ì—ì„œ ê¸°ì˜¨ ì¶”ì¶œ
            weather_info = self.weather_agent.extract_weather_info_from_message(state.final_message)
            
            if weather_info and weather_info.get("temperature") is not None:
                # ì‚¬ìš©ì ì„±ë³„ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì„ì‹œë¡œ "ë‚¨ì„±" ì‚¬ìš©)
                user_gender = "ë‚¨ì„±"  # TODO: ì‹¤ì œ ì‚¬ìš©ì ì •ë³´ì—ì„œ ê°€ì ¸ì˜¤ê¸°
                
                # ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ ì¶”ì²œ ìƒì„±
                recommended_clothing = recommend_clothing_by_weather(
                    weather_info["weather_description"], 
                    user_gender
                )
                
                # CommonSearchë¥¼ ì‚¬ìš©í•´ ì‹¤ì œ ìƒí’ˆ ê²€ìƒ‰
                if recommended_clothing and any(recommended_clothing.values()):
                    weather_products = await self._search_weather_products(
                        recommended_clothing, state, db
                    )
                    
                    if weather_products:
                        # ê¸°ì¡´ ìƒí’ˆ ëª©ë¡ì— ì¶”ê°€
                        state.products.extend(weather_products[:3])  # ìµœëŒ€ 3ê°œ ì¶”ê°€
                        
                        # ë‚ ì”¨ ê¸°ë°˜ ì¶”ì²œë„ recommendation í…Œì´ë¸”ì— ì €ì¥
                        self._save_weather_recommendations(db, state.user_id, weather_info["weather_description"], weather_products[:3])
                        
                        # ì¶”ì²œ ë©”ì‹œì§€ì— ì‹¤ì œ ìƒí’ˆ ì •ë³´ ì¶”ê°€
                        clothing_message = f"\n\nğŸ¯ **ì˜¤ëŠ˜ ë‚ ì”¨ ë§ì¶¤ ìƒí’ˆ**\n"
                        for i, product in enumerate(weather_products[:3], 1):
                            product_name = product.get('ìƒí’ˆëª…', 'ìƒí’ˆëª… ì—†ìŒ')
                            brand = product.get('í•œê¸€ë¸Œëœë“œëª…', 'ë¸Œëœë“œ ì—†ìŒ')
                            price = product.get('ì›ê°€', 0)
                            
                            clothing_message += f"**{i}. {product_name}**\n"
                            clothing_message += f"   ğŸ“ ë¸Œëœë“œ: {brand}\n"
                            if price:
                                clothing_message += f"   ğŸ’° ê°€ê²©: {price:,}ì›\n"
                            clothing_message += "\n"
                        
                        state.final_message += clothing_message
                    else:
                        # ì‹¤ì œ ìƒí’ˆì´ ì—†ìœ¼ë©´ ê¸°ì¡´ ì¹´í…Œê³ ë¦¬ ì¶”ì²œë§Œ í‘œì‹œ
                        clothing_parts = []
                        for category, items in recommended_clothing.items():
                            if items:
                                clothing_parts.append(f"{category}: {', '.join(items)}")
                        
                        if clothing_parts:
                            clothing_message = f"\n\nğŸ¯ **ì˜¤ëŠ˜ ë‚ ì”¨ ì¶”ì²œ**\n{', '.join(clothing_parts)}ì„(ë¥¼) ì¶”ì²œí•´ ë“œë ¤ìš”!"
                            state.final_message += clothing_message
                        
        except Exception as e:
            print(f"ë‚ ì”¨ ì˜ë¥˜ ì¶”ì²œ ì˜¤ë¥˜: {e}")
        
        return state
    
    async def _search_weather_products(self, recommended_clothing: Dict, state: LangGraphState, db) -> List[Dict]:
        """ë‚ ì”¨ ê¸°ë°˜ ì¶”ì²œ ì˜ë¥˜ì˜ ì‹¤ì œ ìƒí’ˆ ê²€ìƒ‰"""
        try:
            from services.common_search import CommonSearchModule, SearchQuery
            from data_store import clothing_data
            
            search_module = CommonSearchModule()
            all_products = []
            
            # ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê²€ìƒ‰
            for category, items in recommended_clothing.items():
                if not items:
                    continue
                    
                # ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
                search_query = SearchQuery(
                    categories=[category] + items,  # ì¹´í…Œê³ ë¦¬ì™€ ì•„ì´í…œë“¤ì„ ëª¨ë‘ ì¹´í…Œê³ ë¦¬ë¡œ ì‚¬ìš©
                    colors=[],  # ìƒ‰ìƒ ì œí•œ ì—†ìŒ
                    situations=["ë‚ ì”¨"],
                    styles=[]
                )
                
                # ìƒí’ˆ ê²€ìƒ‰
                if clothing_data:
                    search_result = search_module.search_products(
                        query=search_query,
                        available_products=clothing_data
                    )
                    
                    if search_result.products:
                        all_products.extend(search_result.products[:2])  # ì¹´í…Œê³ ë¦¬ë‹¹ ìµœëŒ€ 2ê°œ
            
            # ì¤‘ë³µ ì œê±°
            seen_ids = set()
            unique_products = []
            for product in all_products:
                product_id = product.get("ìƒí’ˆì½”ë“œ", "")
                if product_id and product_id not in seen_ids:
                    seen_ids.add(product_id)
                    unique_products.append(product)
            
            print(f"ë‚ ì”¨ ê¸°ë°˜ ìƒí’ˆ ê²€ìƒ‰ ê²°ê³¼: {len(unique_products)}ê°œ")
            return unique_products[:4]  # ìµœëŒ€ 4ê°œ ë°˜í™˜
            
        except Exception as e:
            print(f"ë‚ ì”¨ ìƒí’ˆ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def _save_weather_recommendations(self, db, user_id: int, weather_desc: str, products: List[Dict]):
        """ë‚ ì”¨ ê¸°ë°˜ ì¶”ì²œì„ recommendation í…Œì´ë¸”ì— ì €ì¥ - ì±—ë´‡ ë¼ìš°í„°ì—ì„œë§Œ ì €ì¥í•˜ë„ë¡ ë¹„í™œì„±í™”"""
        # ì±—ë´‡ ë¼ìš°í„°ì—ì„œë§Œ ì¶”ì²œì„ ì €ì¥í•˜ë„ë¡ ë¹„í™œì„±í™”
        # ì¤‘ë³µ ì €ì¥ ë°©ì§€ë¥¼ ìœ„í•´ WeatherAgentì—ì„œëŠ” ì €ì¥í•˜ì§€ ì•ŠìŒ
        print("â„¹ï¸ WeatherAgent: ì¶”ì²œ ì €ì¥ì€ ì±—ë´‡ ë¼ìš°í„°ì—ì„œ ì²˜ë¦¬ë©ë‹ˆë‹¤.")
        return
        
        # ê¸°ì¡´ ì½”ë“œ (ì£¼ì„ ì²˜ë¦¬)
        """
        try:
            from crud.recommendation_crud import create_multiple_recommendations, get_user_recommendations
            
            # ìµœê·¼ ì¶”ì²œ ê¸°ë¡ ì¡°íšŒí•˜ì—¬ ì¤‘ë³µ ì²´í¬
            recent_recommendations = get_user_recommendations(db, user_id, limit=20)
            recent_item_ids = {rec.item_id for rec in recent_recommendations}
            
            recommendations_data = []
            for product in products:
                item_id = product.get("ìƒí’ˆì½”ë“œ", 0)
                if item_id and item_id not in recent_item_ids:
                    recommendations_data.append({
                        "item_id": item_id,
                        "query": f"ë‚ ì”¨ ê¸°ë°˜ ì¶”ì²œ ({weather_desc})",
                        "reason": f"{weather_desc}ì— ì í•©í•œ ì˜ë¥˜"
                    })
                    recent_item_ids.add(item_id)  # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ì¶”ê°€
            
            if recommendations_data:
                create_multiple_recommendations(db, user_id, recommendations_data)
                print(f"âœ… ë‚ ì”¨ ê¸°ë°˜ ì¶”ì²œ {len(recommendations_data)}ê°œë¥¼ recommendation í…Œì´ë¸”ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
            else:
                print("âš ï¸ ì €ì¥í•  ë‚ ì”¨ ì¶”ì²œì´ ì—†ìŠµë‹ˆë‹¤ (ì¤‘ë³µ ì œê±° í›„).")
                
        except Exception as e:
            print(f"âŒ ë‚ ì”¨ ì¶”ì²œ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
            # ì €ì¥ ì‹¤íŒ¨í•´ë„ ì¶”ì²œì€ ê³„ì† ì§„í–‰
        """
    
    # Legacy methods ì™„ì „ ì œê±°ë¨ - LangGraph ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œìœ¼ë¡œ ëŒ€ì²´
    # ëª¨ë“  ì²˜ë¦¬ê°€ _agent_execution_nodeì—ì„œ í†µí•© ì²˜ë¦¬ë¨
