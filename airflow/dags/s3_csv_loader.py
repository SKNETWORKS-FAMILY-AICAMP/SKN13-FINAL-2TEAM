import os
import pandas as pd
import boto3
from botocore.exceptions import ClientError
from dotenv import load_dotenv
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class S3CSVLoader:
    """S3ì—ì„œ CSV íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        # .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
        load_dotenv()
        
        # AWS ì„¤ì •
        self.aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID')
        self.aws_secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY')
        self.aws_region = os.getenv('AWS_REGION', 'ap-northeast-2')
        self.bucket_name = os.getenv('S3_BUCKET_NAME', 'ivle-malle')
        
        # AWS í‚¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        logger.info(f"ğŸ” AWS ì„¤ì • í™•ì¸:")
        logger.info(f"   AWS_ACCESS_KEY_ID: {'ì„¤ì •ë¨' if self.aws_access_key_id else 'ì„¤ì •ë˜ì§€ ì•ŠìŒ'}")
        logger.info(f"   AWS_SECRET_ACCESS_KEY: {'ì„¤ì •ë¨' if self.aws_secret_access_key else 'ì„¤ì •ë˜ì§€ ì•ŠìŒ'}")
        logger.info(f"   AWS_REGION: {self.aws_region}")
        logger.info(f"   S3_BUCKET_NAME: {self.bucket_name}")
        
        # AWS í‚¤ê°€ ì—†ìœ¼ë©´ S3 í´ë¼ì´ì–¸íŠ¸ë¥¼ Noneìœ¼ë¡œ ì„¤ì •
        if not self.aws_access_key_id or not self.aws_secret_access_key:
            logger.error("âŒ AWS í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
            logger.error("   .env íŒŒì¼ì—ì„œ ë‹¤ìŒ ë³€ìˆ˜ë“¤ì„ ì„¤ì •í•´ì£¼ì„¸ìš”:")
            logger.error("   - AWS_ACCESS_KEY_ID")
            logger.error("   - AWS_SECRET_ACCESS_KEY")
            logger.error("   - AWS_REGION (ì„ íƒì‚¬í•­)")
            logger.error("   - S3_BUCKET_NAME (ì„ íƒì‚¬í•­)")
            self.s3_client = None
            return
        
        # S3 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            self.s3_client = boto3.client(
                's3',
                aws_access_key_id=self.aws_access_key_id,
                aws_secret_access_key=self.aws_secret_access_key,
                region_name=self.aws_region
            )
            logger.info(f"âœ… S3 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ: {self.bucket_name}")
        except Exception as e:
            logger.error(f"âŒ S3 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.s3_client = None
    
    def load_csv_from_s3(self, s3_key, encoding='utf-8'):
        """
        S3ì—ì„œ CSV íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ pandas DataFrameìœ¼ë¡œ ë°˜í™˜
        
        Args:
            s3_key (str): S3 ê°ì²´ í‚¤ (ì˜ˆ: 'musinsa_csvs/2025-08-06/product_info_combined_1357.csv')
            encoding (str): íŒŒì¼ ì¸ì½”ë”© (ê¸°ë³¸ê°’: 'utf-8')
        
        Returns:
            pandas.DataFrame: ë¡œë“œëœ CSV ë°ì´í„°
        """
        if not self.s3_client:
            logger.error("âŒ S3 í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        try:
            logger.info(f"ğŸ“¥ S3ì—ì„œ CSV íŒŒì¼ ë¡œë“œ ì¤‘: s3://{self.bucket_name}/{s3_key}")
            
            # S3ì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            response = self.s3_client.get_object(Bucket=self.bucket_name, Key=s3_key)
            
            # CSV ë°ì´í„° ì½ê¸°
            df = pd.read_csv(response['Body'], encoding=encoding)
            
            logger.info(f"âœ… CSV íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {len(df)} í–‰, {len(df.columns)} ì—´")
            logger.info(f"ğŸ“Š ì»¬ëŸ¼: {list(df.columns)}")
            
            return df
            
        except ClientError as e:
            error_code = e.response['Error']['Code']
            if error_code == 'NoSuchKey':
                logger.error(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: s3://{self.bucket_name}/{s3_key}")
            elif error_code == 'NoSuchBucket':
                logger.error(f"âŒ ë²„í‚·ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.bucket_name}")
            else:
                logger.error(f"âŒ S3 ì˜¤ë¥˜: {e}")
            return None
        except Exception as e:
            logger.error(f"âŒ CSV íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def list_csv_files(self, prefix='musinsa_csvs/'):
        """
        S3 ë²„í‚·ì—ì„œ íŠ¹ì • ì ‘ë‘ì‚¬ë¡œ ì‹œì‘í•˜ëŠ” CSV íŒŒì¼ ëª©ë¡ì„ ë°˜í™˜
        
        Args:
            prefix (str): ê²€ìƒ‰í•  ì ‘ë‘ì‚¬ (ê¸°ë³¸ê°’: 'musinsa_csvs/')
        
        Returns:
            list: CSV íŒŒì¼ í‚¤ ëª©ë¡
        """
        if not self.s3_client:
            logger.error("âŒ S3 í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        try:
            logger.info(f"ğŸ” S3ì—ì„œ CSV íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì¤‘: s3://{self.bucket_name}/{prefix}")
            
            response = self.s3_client.list_objects_v2(
                Bucket=self.bucket_name,
                Prefix=prefix
            )
            
            csv_files = []
            if 'Contents' in response:
                for obj in response['Contents']:
                    if obj['Key'].endswith('.csv'):
                        csv_files.append(obj['Key'])
            
            logger.info(f"âœ… CSV íŒŒì¼ {len(csv_files)}ê°œ ë°œê²¬")
            for file_key in csv_files:
                logger.info(f"   ğŸ“„ {file_key}")
            
            return csv_files
            
        except Exception as e:
            logger.error(f"âŒ CSV íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def get_latest_date_csv_files(self, base_prefix='musinsa_csvs/'):
        """
        ê°€ì¥ ìµœê·¼ ë‚ ì§œì˜ CSV íŒŒì¼ë“¤ì„ ì°¾ì•„ì„œ ë°˜í™˜
        
        Args:
            base_prefix (str): ê¸°ë³¸ ì ‘ë‘ì‚¬ (ê¸°ë³¸ê°’: 'musinsa_csvs/')
        
        Returns:
            tuple: (ìµœê·¼ ë‚ ì§œ, CSV íŒŒì¼ í‚¤ ë¦¬ìŠ¤íŠ¸)
        """
        if not self.s3_client:
            logger.error("âŒ S3 í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None, []
        
        try:
            logger.info(f"ğŸ” ê°€ì¥ ìµœê·¼ ë‚ ì§œì˜ CSV íŒŒì¼ ê²€ìƒ‰ ì¤‘: s3://{self.bucket_name}/{base_prefix}")
            
            # ëª¨ë“  ê°ì²´ ì¡°íšŒ
            response = self.s3_client.list_objects_v2(
                Bucket=self.bucket_name,
                Prefix=base_prefix
            )
            
            if 'Contents' not in response:
                logger.warning(f"âš ï¸ {base_prefix} ì ‘ë‘ì‚¬ë¡œ ì‹œì‘í•˜ëŠ” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return None, []
            
            # ë‚ ì§œë³„ë¡œ íŒŒì¼ ê·¸ë£¹í™”
            date_files = {}
            for obj in response['Contents']:
                key = obj['Key']
                if key.endswith('.csv'):
                    # ë‚ ì§œ ì¶”ì¶œ (musinsa_csvs/YYYY-MM-DD/filename.csv)
                    parts = key.split('/')
                    if len(parts) >= 3:
                        date_str = parts[1]  # YYYY-MM-DD
                        if date_str not in date_files:
                            date_files[date_str] = []
                        date_files[date_str].append(key)
            
            if not date_files:
                logger.warning(f"âš ï¸ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None, []
            
            # ê°€ì¥ ìµœê·¼ ë‚ ì§œ ì°¾ê¸°
            latest_date = max(date_files.keys())
            latest_files = date_files[latest_date]
            
            logger.info(f"âœ… ê°€ì¥ ìµœê·¼ ë‚ ì§œ: {latest_date}")
            logger.info(f"ğŸ“„ í•´ë‹¹ ë‚ ì§œì˜ CSV íŒŒì¼ {len(latest_files)}ê°œ:")
            for file_key in latest_files:
                logger.info(f"   ğŸ“„ {file_key}")
            
            return latest_date, latest_files
            
        except Exception as e:
            logger.error(f"âŒ ìµœê·¼ ë‚ ì§œ CSV íŒŒì¼ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None, []
    
    def load_latest_csv_files(self, base_prefix='musinsa_csvs/', max_files=None):
        """
        ê°€ì¥ ìµœê·¼ ë‚ ì§œì˜ CSV íŒŒì¼ë“¤ì„ ë¡œë“œ
        
        Args:
            base_prefix (str): ê¸°ë³¸ ì ‘ë‘ì‚¬ (ê¸°ë³¸ê°’: 'musinsa_csvs/')
            max_files (int): ìµœëŒ€ ë¡œë“œí•  íŒŒì¼ ìˆ˜ (Noneì´ë©´ ëª¨ë‘ ë¡œë“œ)
        
        Returns:
            tuple: (ìµœê·¼ ë‚ ì§œ, pandas.DataFrame ë¦¬ìŠ¤íŠ¸)
        """
        latest_date, csv_files = self.get_latest_date_csv_files(base_prefix)
        
        if not csv_files:
            logger.error("âŒ ë¡œë“œí•  CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None, []
        
        # íŒŒì¼ ìˆ˜ ì œí•œ
        if max_files and len(csv_files) > max_files:
            csv_files = csv_files[:max_files]
            logger.info(f"ğŸ“ ìµœëŒ€ {max_files}ê°œ íŒŒì¼ë§Œ ë¡œë“œí•©ë‹ˆë‹¤.")
        
        # CSV íŒŒì¼ë“¤ ë¡œë“œ
        dataframes = []
        for s3_key in csv_files:
            df = self.load_csv_from_s3(s3_key)
            if df is not None:
                dataframes.append(df)
                logger.info(f"âœ… {s3_key} ë¡œë“œ ì™„ë£Œ")
            else:
                logger.warning(f"âš ï¸ {s3_key} ë¡œë“œ ì‹¤íŒ¨")
        
        return latest_date, dataframes
    
    def load_multiple_csvs(self, s3_keys, encoding='utf-8'):
        """
        ì—¬ëŸ¬ CSV íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
        
        Args:
            s3_keys (list): S3 ê°ì²´ í‚¤ ë¦¬ìŠ¤íŠ¸
            encoding (str): íŒŒì¼ ì¸ì½”ë”© (ê¸°ë³¸ê°’: 'utf-8')
        
        Returns:
            list: pandas.DataFrame ë¦¬ìŠ¤íŠ¸
        """
        dataframes = []
        
        for s3_key in s3_keys:
            df = self.load_csv_from_s3(s3_key, encoding)
            if df is not None:
                dataframes.append(df)
                logger.info(f"âœ… {s3_key} ë¡œë“œ ì™„ë£Œ")
            else:
                logger.warning(f"âš ï¸ {s3_key} ë¡œë“œ ì‹¤íŒ¨")
        
        return dataframes

def main():
    """ë©”ì¸ í•¨ìˆ˜ - ì˜ˆì œ ì‚¬ìš©ë²•"""
    # S3CSVLoader ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    loader = S3CSVLoader()
    
    # ê°€ì¥ ìµœê·¼ ë‚ ì§œì˜ CSV íŒŒì¼ë“¤ ë¡œë“œ
    print("ğŸš€ ê°€ì¥ ìµœê·¼ ë‚ ì§œì˜ CSV íŒŒì¼ë“¤ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
    latest_date, dataframes = loader.load_latest_csv_files(max_files=5)  # ìµœëŒ€ 5ê°œ íŒŒì¼ë§Œ ë¡œë“œ
    
    if latest_date and dataframes:
        print(f"\nâœ… {latest_date} ë‚ ì§œì˜ CSV íŒŒì¼ {len(dataframes)}ê°œ ë¡œë“œ ì™„ë£Œ!")
        
        # ê° DataFrame ì •ë³´ ì¶œë ¥
        for i, df in enumerate(dataframes):
            print(f"\nğŸ“Š DataFrame {i+1}:")
            print(f"   ğŸ“ˆ í¬ê¸°: {df.shape}")
            print(f"   ğŸ“‹ ì»¬ëŸ¼: {list(df.columns)}")
            print(f"   ğŸ” ì²˜ìŒ 3í–‰:")
            print(df.head(3))
    else:
        print("âŒ CSV íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨!")
    
    # íŠ¹ì • CSV íŒŒì¼ ë¡œë“œ ì˜ˆì œ (ê¸°ì¡´ ë°©ì‹)
    print(f"\nğŸ” íŠ¹ì • íŒŒì¼ ë¡œë“œ ì˜ˆì œ:")
    s3_key = "musinsa_csvs/2025-08-06/product_info_combined_1357.csv"
    df = loader.load_csv_from_s3(s3_key)
    
    if df is not None:
        print(f"âœ… íŠ¹ì • íŒŒì¼ ë¡œë“œ ì„±ê³µ: {len(df)} í–‰")
    else:
        print("âŒ íŠ¹ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨!")

if __name__ == "__main__":
    main()
